{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exceptions import DataPipelineError, FeatureEngineeringError\n",
    "\n",
    "from data.data_pipeline import DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class DataStatus:\n",
    "    raw_count: int\n",
    "    processed_count: int\n",
    "    universe_count: int\n",
    "    raw_symbols: list\n",
    "    processed_symbols: list\n",
    "    universe_symbols: list\n",
    "    columns: list\n",
    "\n",
    "def format_data_status(pipeline) -> str:\n",
    "    \"\"\"\n",
    "    Format the data status output in a readable table format.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: DataPipeline instance\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string with data status information\n",
    "    \"\"\"\n",
    "    status = pipeline.check_data_status()\n",
    "    \n",
    "    # Create DataStatus object for easier handling\n",
    "    data_status = DataStatus(\n",
    "        raw_count=status['raw_data']['count'],\n",
    "        processed_count=status['processed_data']['count'],\n",
    "        universe_count=status['universe']['count'],\n",
    "        raw_symbols=status['raw_data']['symbols'],\n",
    "        processed_symbols=status['processed_data']['symbols'],\n",
    "        universe_symbols=status['universe']['symbols'],\n",
    "        columns=status['raw_data']['sample_columns'] if status['raw_data']['count'] > 0 else []\n",
    "    )\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_data = [\n",
    "        [\"Raw Data\", data_status.raw_count, \", \".join(data_status.raw_symbols[:3]) + (\"...\" if len(data_status.raw_symbols) > 3 else \"\")],\n",
    "        [\"Processed Data\", data_status.processed_count, \", \".join(data_status.processed_symbols[:3]) + (\"...\" if len(data_status.processed_symbols) > 3 else \"\")],\n",
    "        [\"Universe\", data_status.universe_count, \", \".join(data_status.universe_symbols[:3]) + (\"...\" if len(data_status.universe_symbols) > 3 else \"\")]\n",
    "    ]\n",
    "    \n",
    "    summary_table = tabulate(summary_data, \n",
    "                           headers=[\"Stage\", \"Count\", \"Sample Symbols\"],\n",
    "                           tablefmt=\"grid\")\n",
    "    \n",
    "    # Create columns table if available\n",
    "    columns_str = \"\"\n",
    "    if data_status.columns:\n",
    "        columns_table = tabulate([[\"Available Columns\", \", \".join(data_status.columns)]], \n",
    "                               tablefmt=\"grid\")\n",
    "        columns_str = f\"\\n\\nColumns:\\n{columns_table}\"\n",
    "    \n",
    "    return f\"Data Pipeline Status:\\n{summary_table}{columns_str}\"\n",
    "\n",
    "def format_data_quality(pipeline) -> str:\n",
    "    \"\"\"\n",
    "    Format the data quality metrics in a readable table format.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: DataPipeline instance\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string with data quality information\n",
    "    \"\"\"\n",
    "    quality_metrics = pipeline.validate_data_quality()\n",
    "    \n",
    "    # Prepare data for main metrics table\n",
    "    metrics_data = []\n",
    "    for symbol, metrics in quality_metrics.items():\n",
    "        metrics_data.append([\n",
    "            symbol,\n",
    "            metrics['data_points'],\n",
    "            metrics['missing_values'],\n",
    "            f\"{metrics['avg_volume']:,.0f}\",\n",
    "            metrics['zero_volume_days'],\n",
    "            metrics['start_date'].strftime('%Y-%m-%d'),\n",
    "            metrics['end_date'].strftime('%Y-%m-%d')\n",
    "        ])\n",
    "    \n",
    "    # Create main metrics table\n",
    "    metrics_table = tabulate(metrics_data,\n",
    "                           headers=[\"Symbol\", \"Data Points\", \"Missing Values\", \n",
    "                                  \"Avg Volume\", \"Zero Volume Days\", \n",
    "                                  \"Start Date\", \"End Date\"],\n",
    "                           tablefmt=\"grid\")\n",
    "    \n",
    "    # Calculate and format summary statistics\n",
    "    total_data_points = sum(m['data_points'] for m in quality_metrics.values())\n",
    "    total_missing = sum(m['missing_values'] for m in quality_metrics.values())\n",
    "    avg_missing = total_missing / len(quality_metrics) if quality_metrics else 0\n",
    "    \n",
    "    summary_data = [\n",
    "        [\"Total Symbols\", len(quality_metrics)],\n",
    "        [\"Total Data Points\", total_data_points],\n",
    "        [\"Average Missing Values\", f\"{avg_missing:.2f}\"],\n",
    "        [\"Date Range\", f\"{min((m['start_date'] for m in quality_metrics.values())).strftime('%Y-%m-%d')} to \"\n",
    "                      f\"{max((m['end_date'] for m in quality_metrics.values())).strftime('%Y-%m-%d')}\"]\n",
    "    ]\n",
    "    \n",
    "    summary_table = tabulate(summary_data,\n",
    "                           headers=[\"Metric\", \"Value\"],\n",
    "                           tablefmt=\"grid\")\n",
    "    \n",
    "    return f\"Data Quality Summary:\\n{summary_table}\\n\\nDetailed Metrics by Symbol:\\n{metrics_table}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:47:32 - DataPipeline - INFO - Fetching data for 14 symbols...\n",
      "19:47:32 - DataPipeline - INFO - Successfully fetched data for 14 symbols\n",
      "\n",
      "Status after fetch:\n",
      "Data Pipeline Status:\n",
      "+----------------+---------+---------------------+\n",
      "| Stage          |   Count | Sample Symbols      |\n",
      "+================+=========+=====================+\n",
      "| Raw Data       |      14 | TSLA, NVDA, META... |\n",
      "+----------------+---------+---------------------+\n",
      "| Processed Data |       0 |                     |\n",
      "+----------------+---------+---------------------+\n",
      "| Universe       |       0 |                     |\n",
      "+----------------+---------+---------------------+\n",
      "\n",
      "Columns:\n",
      "+-------------------+---------------------------------------------------------+\n",
      "| Available Columns | Open, High, Low, Close, Volume, Dividends, Stock Splits |\n",
      "+-------------------+---------------------------------------------------------+\n",
      "19:47:32 - DataPipeline - INFO - Starting data processing with 14 symbols\n",
      "19:47:32 - DataPipeline - INFO - Processed data for 14 symbols\n",
      "\n",
      "Quality after processing:\n",
      "Data Quality Summary:\n",
      "+------------------------+--------------------------+\n",
      "| Metric                 | Value                    |\n",
      "+========================+==========================+\n",
      "| Total Symbols          | 14                       |\n",
      "+------------------------+--------------------------+\n",
      "| Total Data Points      | 48587                    |\n",
      "+------------------------+--------------------------+\n",
      "| Average Missing Values | 60.00                    |\n",
      "+------------------------+--------------------------+\n",
      "| Date Range             | 2010-01-04 to 2023-12-29 |\n",
      "+------------------------+--------------------------+\n",
      "\n",
      "Detailed Metrics by Symbol:\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| Symbol   |   Data Points |   Missing Values | Avg Volume   |   Zero Volume Days | Start Date   | End Date   |\n",
      "+==========+===============+==================+==============+====================+==============+============+\n",
      "| TSLA     |          3400 |               60 | 96,811,665   |                  0 | 2010-06-29   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| NVDA     |          3522 |               60 | 505,556,007  |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| META     |          2923 |               60 | 30,604,725   |                  0 | 2012-05-18   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| AMZN     |          3522 |               60 | 86,238,044   |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| JPM      |          3522 |               60 | 20,001,582   |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| JNJ      |          3522 |               60 | 8,788,027    |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| WMT      |          3522 |               60 | 26,303,760   |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| PG       |          3522 |               60 | 8,903,353    |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| XOM      |          3522 |               60 | 17,579,803   |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| BAC      |          3522 |               60 | 100,680,640  |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| HD       |          3522 |               60 | 6,489,105    |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| COST     |          3522 |               60 | 2,423,384    |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| V        |          3522 |               60 | 11,572,262   |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "| DIS      |          3522 |               60 | 9,997,458    |                  0 | 2010-01-04   | 2023-12-29 |\n",
      "+----------+---------------+------------------+--------------+--------------------+--------------+------------+\n",
      "19:47:32 - DataPipeline - INFO - Created universe with 14 symbols\n",
      "\n",
      "Status after creating universe:\n",
      "19:47:32 - DataPipeline - INFO - Starting get_training_data...\n",
      "19:47:32 - DataPipeline - INFO - Preparing features and targets...\n",
      "19:47:32 - DataPipeline - INFO - Starting feature preparation with 14 symbols\n",
      "19:47:32 - DataPipeline - INFO - Processing symbol NVDA (1/14)\n",
      "19:47:32 - DataPipeline - INFO - NVDA: Processing 3497 potential samples\n",
      "19:47:34 - DataPipeline - INFO - NVDA: Processed 1000 samples\n",
      "19:47:38 - DataPipeline - INFO - NVDA: Processed 2000 samples\n",
      "19:47:40 - DataPipeline - INFO - NVDA: Processed 3000 samples\n",
      "19:47:41 - DataPipeline - INFO - Completed NVDA with 3438 valid samples\n",
      "19:47:41 - DataPipeline - INFO - Processing symbol BAC (2/14)\n",
      "19:47:41 - DataPipeline - INFO - BAC: Processing 3497 potential samples\n",
      "19:47:43 - DataPipeline - INFO - BAC: Processed 1000 samples\n",
      "19:47:45 - DataPipeline - INFO - BAC: Processed 2000 samples\n",
      "19:47:47 - DataPipeline - INFO - BAC: Processed 3000 samples\n",
      "19:47:48 - DataPipeline - INFO - Completed BAC with 3438 valid samples\n",
      "19:47:48 - DataPipeline - INFO - Processing symbol TSLA (3/14)\n",
      "19:47:48 - DataPipeline - INFO - TSLA: Processing 3375 potential samples\n",
      "19:47:50 - DataPipeline - INFO - TSLA: Processed 1000 samples\n",
      "19:47:52 - DataPipeline - INFO - TSLA: Processed 2000 samples\n",
      "19:47:53 - DataPipeline - INFO - TSLA: Processed 3000 samples\n",
      "19:47:54 - DataPipeline - INFO - Completed TSLA with 3316 valid samples\n",
      "19:47:54 - DataPipeline - INFO - Processing symbol AMZN (4/14)\n",
      "19:47:54 - DataPipeline - INFO - AMZN: Processing 3497 potential samples\n",
      "19:47:56 - DataPipeline - INFO - AMZN: Processed 1000 samples\n",
      "19:47:58 - DataPipeline - INFO - AMZN: Processed 2000 samples\n",
      "19:48:00 - DataPipeline - INFO - AMZN: Processed 3000 samples\n",
      "19:48:01 - DataPipeline - INFO - Completed AMZN with 3438 valid samples\n",
      "19:48:01 - DataPipeline - INFO - Processing symbol META (5/14)\n",
      "19:48:01 - DataPipeline - INFO - META: Processing 2898 potential samples\n",
      "19:48:03 - DataPipeline - INFO - META: Processed 1000 samples\n",
      "19:48:05 - DataPipeline - INFO - META: Processed 2000 samples\n",
      "19:48:07 - DataPipeline - INFO - Completed META with 2839 valid samples\n",
      "19:48:07 - DataPipeline - INFO - Processing symbol WMT (6/14)\n",
      "19:48:07 - DataPipeline - INFO - WMT: Processing 3497 potential samples\n",
      "19:48:09 - DataPipeline - INFO - WMT: Processed 1000 samples\n",
      "19:48:11 - DataPipeline - INFO - WMT: Processed 2000 samples\n",
      "19:48:13 - DataPipeline - INFO - WMT: Processed 3000 samples\n",
      "19:48:13 - DataPipeline - INFO - Completed WMT with 3438 valid samples\n",
      "19:48:13 - DataPipeline - INFO - Processing symbol JPM (7/14)\n",
      "19:48:13 - DataPipeline - INFO - JPM: Processing 3497 potential samples\n",
      "19:48:15 - DataPipeline - INFO - JPM: Processed 1000 samples\n",
      "19:48:17 - DataPipeline - INFO - JPM: Processed 2000 samples\n",
      "19:48:19 - DataPipeline - INFO - JPM: Processed 3000 samples\n",
      "19:48:20 - DataPipeline - INFO - Completed JPM with 3438 valid samples\n",
      "19:48:20 - DataPipeline - INFO - Processing symbol XOM (8/14)\n",
      "19:48:20 - DataPipeline - INFO - XOM: Processing 3497 potential samples\n",
      "19:48:22 - DataPipeline - INFO - XOM: Processed 1000 samples\n",
      "19:48:24 - DataPipeline - INFO - XOM: Processed 2000 samples\n",
      "19:48:26 - DataPipeline - INFO - XOM: Processed 3000 samples\n",
      "19:48:27 - DataPipeline - INFO - Completed XOM with 3438 valid samples\n",
      "19:48:27 - DataPipeline - INFO - Processing symbol V (9/14)\n",
      "19:48:27 - DataPipeline - INFO - V: Processing 3497 potential samples\n",
      "19:48:29 - DataPipeline - INFO - V: Processed 1000 samples\n",
      "19:48:31 - DataPipeline - INFO - V: Processed 2000 samples\n",
      "19:48:33 - DataPipeline - INFO - V: Processed 3000 samples\n",
      "19:48:34 - DataPipeline - INFO - Completed V with 3438 valid samples\n",
      "19:48:34 - DataPipeline - INFO - Processing symbol DIS (10/14)\n",
      "19:48:34 - DataPipeline - INFO - DIS: Processing 3497 potential samples\n",
      "19:48:36 - DataPipeline - INFO - DIS: Processed 1000 samples\n",
      "19:48:38 - DataPipeline - INFO - DIS: Processed 2000 samples\n",
      "19:48:39 - DataPipeline - INFO - DIS: Processed 3000 samples\n",
      "19:48:40 - DataPipeline - INFO - Completed DIS with 3438 valid samples\n",
      "19:48:40 - DataPipeline - INFO - Processing symbol PG (11/14)\n",
      "19:48:40 - DataPipeline - INFO - PG: Processing 3497 potential samples\n",
      "19:48:42 - DataPipeline - INFO - PG: Processed 1000 samples\n",
      "19:48:44 - DataPipeline - INFO - PG: Processed 2000 samples\n",
      "19:48:46 - DataPipeline - INFO - PG: Processed 3000 samples\n",
      "19:48:47 - DataPipeline - INFO - Completed PG with 3438 valid samples\n",
      "19:48:47 - DataPipeline - INFO - Processing symbol JNJ (12/14)\n",
      "19:48:47 - DataPipeline - INFO - JNJ: Processing 3497 potential samples\n",
      "19:48:49 - DataPipeline - INFO - JNJ: Processed 1000 samples\n",
      "19:48:51 - DataPipeline - INFO - JNJ: Processed 2000 samples\n",
      "19:48:53 - DataPipeline - INFO - JNJ: Processed 3000 samples\n",
      "19:48:54 - DataPipeline - INFO - Completed JNJ with 3438 valid samples\n",
      "19:48:54 - DataPipeline - INFO - Processing symbol HD (13/14)\n",
      "19:48:54 - DataPipeline - INFO - HD: Processing 3497 potential samples\n",
      "19:48:56 - DataPipeline - INFO - HD: Processed 1000 samples\n",
      "19:48:58 - DataPipeline - INFO - HD: Processed 2000 samples\n",
      "19:49:00 - DataPipeline - INFO - HD: Processed 3000 samples\n",
      "19:49:01 - DataPipeline - INFO - Completed HD with 3438 valid samples\n",
      "19:49:01 - DataPipeline - INFO - Processing symbol COST (14/14)\n",
      "19:49:01 - DataPipeline - INFO - COST: Processing 3497 potential samples\n",
      "19:49:03 - DataPipeline - INFO - COST: Processed 1000 samples\n",
      "19:49:05 - DataPipeline - INFO - COST: Processed 2000 samples\n",
      "19:49:06 - DataPipeline - INFO - COST: Processed 3000 samples\n",
      "19:49:07 - DataPipeline - INFO - Completed COST with 3438 valid samples\n",
      "19:49:07 - DataPipeline - INFO - Feature generation complete. Total samples: 47411\n",
      "19:49:07 - DataPipeline - INFO - Creating features array...\n",
      "19:49:07 - DataPipeline - INFO - Creating features DataFrame...\n",
      "19:49:08 - DataPipeline - INFO - Creating targets series...\n",
      "19:49:08 - DataPipeline - INFO - Applying normalization...\n",
      "19:49:08 - DataPipeline - INFO - Starting normalization for DataFrame of shape (47411, 1180)\n",
      "19:49:08 - DataPipeline - INFO - Processing 3438 unique dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 0/3438 dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 100/3438 dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 200/3438 dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 300/3438 dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 400/3438 dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 500/3438 dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 600/3438 dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 700/3438 dates\n",
      "19:49:08 - DataPipeline - INFO - Processed 800/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 900/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1000/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1100/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1200/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1300/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1400/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1500/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1600/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1700/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1800/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 1900/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 2000/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 2100/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 2200/3438 dates\n",
      "19:49:09 - DataPipeline - INFO - Processed 2300/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 2400/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 2500/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 2600/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 2700/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 2800/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 2900/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 3000/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 3100/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 3200/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 3300/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Processed 3400/3438 dates\n",
      "19:49:10 - DataPipeline - INFO - Normalization complete\n",
      "19:49:10 - DataPipeline - INFO - Feature preparation complete\n",
      "19:49:10 - DataPipeline - INFO - Features shape: (47411, 1180)\n",
      "19:49:10 - DataPipeline - INFO - Targets shape: 47411\n",
      "19:49:10 - DataPipeline - INFO - Checking index alignment...\n",
      "19:49:10 - DataPipeline - INFO - Sorting indices...\n",
      "19:49:11 - DataPipeline - INFO - Calculating split point...\n",
      "19:49:11 - DataPipeline - INFO - Total unique dates: 3438\n",
      "19:49:11 - DataPipeline - INFO - Split date calculated: 2021-03-31 00:00:00-04:00\n",
      "19:49:11 - DataPipeline - INFO - Splitting data...\n",
      "19:49:11 - DataPipeline - INFO - X_train split complete\n",
      "19:49:11 - DataPipeline - INFO - X_test split complete\n",
      "19:49:11 - DataPipeline - INFO - y_train split complete\n",
      "19:49:11 - DataPipeline - INFO - y_test split complete\n",
      "19:49:11 - DataPipeline - INFO - Training data from 2010-04-28 00:00:00-04:00 to 2021-03-31 00:00:00-04:00\n",
      "19:49:11 - DataPipeline - INFO - Testing data from 2021-03-31 00:00:00-04:00 to 2023-12-21 00:00:00-05:00\n",
      "19:49:11 - DataPipeline - INFO - Training samples: 37793, Testing samples: 9618\n",
      "\n",
      "I got the training data with shapes: (37793, 1180) and (9618, 1180)\n",
      "\n",
      "X_train shape: (37793, 1180)\n",
      "X_test shape: (9618, 1180)\n"
     ]
    }
   ],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = DataPipeline(\n",
    "    start_date='2010-01-01',\n",
    "    end_date='2023-12-31',\n",
    "    universe_size=500,\n",
    "    cache_dir='data/cache',\n",
    "    price_col='Close'\n",
    ")\n",
    "\n",
    "# Fetch data\n",
    "symbols = [\n",
    "    'AMZN', 'META', 'NVDA', 'TSLA', 'JPM', 'JNJ', 'WMT', \n",
    "    'PG', 'XOM', 'BAC', 'HD', 'COST', 'V', 'DIS'\n",
    "]\n",
    "pipeline.fetch_data(symbols)\n",
    "\n",
    "# Check status after fetch\n",
    "print(\"\\nStatus after fetch:\")\n",
    "print(format_data_status(pipeline))\n",
    "\n",
    "# Process data\n",
    "pipeline.process_data()\n",
    "\n",
    "# Check quality after processing\n",
    "print(\"\\nQuality after processing:\")\n",
    "print(format_data_quality(pipeline))\n",
    "\n",
    "# Create universe\n",
    "pipeline.create_universe()\n",
    "\n",
    "print(\"\\nStatus after creating universe:\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = pipeline.get_training_data()\n",
    "\n",
    "# Check status after creating universe\n",
    "print(f\"\\nI got the training data with shapes: {X_train.shape} and {X_test.shape}\")\n",
    "\n",
    "print(\"\\nX_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:50:07 - DataPipeline - INFO - Filtered universe contains 4 symbols\n",
      "Mean Reversion Positions:\n",
      "----------------------------------------\n",
      "Long positions (0): []\n",
      "Short positions (0): []\n"
     ]
    }
   ],
   "source": [
    "from models.mean_reversion_analyzer import MeanReversionAnalyzer\n",
    "\n",
    "# Initialize mean reversion analyzer with our existing pipeline\n",
    "mean_reversion = MeanReversionAnalyzer(\n",
    "    data_pipeline=pipeline,\n",
    "    lookback_periods=20,\n",
    "    z_score_threshold=2.0,\n",
    "    volume_percentile=0.7,\n",
    "    max_positions=5\n",
    ")\n",
    "\n",
    "# Generate signals and store them\n",
    "signals = mean_reversion.generate_signals()\n",
    "\n",
    "# Display initial results\n",
    "print(\"Mean Reversion Positions:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Long positions ({len(signals.longs)}):\", signals.longs)\n",
    "print(f\"Short positions ({len(signals.shorts)}):\", signals.shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current universe: ['NVDA', 'BAC', 'TSLA', 'AMZN', 'META', 'WMT', 'JPM', 'XOM', 'V', 'DIS', 'PG', 'JNJ', 'HD', 'COST']\n",
      "\n",
      "Filtered universe: ['NVDA', 'BAC', 'TSLA', 'AMZN']\n",
      "\n",
      "Z-scores for NVDA:\n",
      "Latest z-score: 1.028\n",
      "\n",
      "Z-scores for BAC:\n",
      "Latest z-score: 0.918\n",
      "\n",
      "Z-scores for TSLA:\n",
      "Latest z-score: 0.170\n",
      "\n",
      "Z-scores for AMZN:\n",
      "Latest z-score: 0.619\n",
      "\n",
      "Z-scores for META:\n",
      "Latest z-score: 1.057\n",
      "\n",
      "Z-scores for WMT:\n",
      "Latest z-score: 1.539\n",
      "\n",
      "Z-scores for JPM:\n",
      "Latest z-score: 1.320\n",
      "\n",
      "Z-scores for XOM:\n",
      "Latest z-score: -0.535\n",
      "\n",
      "Z-scores for V:\n",
      "Latest z-score: 1.074\n",
      "\n",
      "Z-scores for DIS:\n",
      "Latest z-score: -1.341\n",
      "\n",
      "Z-scores for PG:\n",
      "Latest z-score: 0.044\n",
      "\n",
      "Z-scores for JNJ:\n",
      "Latest z-score: 0.474\n",
      "\n",
      "Z-scores for HD:\n",
      "Latest z-score: 0.545\n",
      "\n",
      "Z-scores for COST:\n",
      "Latest z-score: 0.984\n"
     ]
    }
   ],
   "source": [
    "# First, let's check what our universe looks like\n",
    "print(\"Current universe:\", pipeline.universe)\n",
    "\n",
    "# Let's examine the filtering process\n",
    "filtered_universe = mean_reversion.filter_universe()\n",
    "print(\"\\nFiltered universe:\", filtered_universe)\n",
    "\n",
    "# Let's look at the actual z-scores before thresholding\n",
    "for symbol in pipeline.universe:\n",
    "    data = pipeline.processed_data[symbol]\n",
    "    z_scores = mean_reversion.calculate_z_scores(data)\n",
    "    print(f\"\\nZ-scores for {symbol}:\")\n",
    "    print(f\"Latest z-score: {z_scores.iloc[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:22:17 - DataPipeline - INFO - Initializing model pipeline with catboost model\n",
      "20:22:59 - DataPipeline - INFO - Model Evaluation Results:\n",
      "20:22:59 - DataPipeline - INFO - mse: 0.0023\n",
      "20:22:59 - DataPipeline - INFO - rmse: 0.0475\n",
      "20:22:59 - DataPipeline - INFO - mae: 0.0331\n",
      "20:22:59 - DataPipeline - INFO - r2: 0.0009\n",
      "20:22:59 - DataPipeline - INFO - directional_accuracy: 0.5336\n",
      "20:22:59 - DataPipeline - INFO - precision: 0.5335\n",
      "20:22:59 - DataPipeline - INFO - recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mse': 0.0022570872058955507,\n",
       " 'rmse': 0.04750881187627776,\n",
       " 'mae': 0.03314557189254731,\n",
       " 'r2': 0.000917019937664354,\n",
       " 'directional_accuracy': 0.5335828654605947,\n",
       " 'precision': 0.533534366226474,\n",
       " 'recall': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "from config.settings import DEFAULT_MODEL_TYPE\n",
    "from models.model_pipeline import ModelPipeline\n",
    "\n",
    "# Initialize pipeline\n",
    "model = ModelPipeline()\n",
    "\n",
    "# Train model\n",
    "model.train(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "model.evaluate_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Portfolio Strategy\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Testing Monthly Metrics Calculation...\n",
      "Monthly returns shape: (168, 14)\n",
      "Monthly volumes shape: (168, 14)\n",
      "\n",
      "Sample of monthly returns:\n",
      "                             NVDA     BAC    TSLA    AMZN    META     WMT  \\\n",
      "Date                                                                        \n",
      "2023-08-31 00:00:00-04:00  0.0562 -0.0966 -0.0350  0.0324 -0.0713  0.0208   \n",
      "2023-09-30 00:00:00-04:00 -0.1186 -0.0450 -0.0305 -0.0789  0.0146 -0.0165   \n",
      "2023-10-31 00:00:00-04:00 -0.0625 -0.0380 -0.1973  0.0470  0.0035  0.0218   \n",
      "2023-11-30 00:00:00-05:00  0.1469  0.1668  0.1954  0.0977  0.0859 -0.0472   \n",
      "2023-12-31 00:00:00-05:00  0.0589  0.1043  0.0350  0.0400  0.0820  0.0163   \n",
      "\n",
      "                              JPM     XOM       V     DIS      PG     JNJ  \\\n",
      "Date                                                                        \n",
      "2023-08-31 00:00:00-04:00 -0.0736  0.0453  0.0354 -0.0586 -0.0125 -0.0279   \n",
      "2023-09-30 00:00:00-04:00 -0.0090  0.0575 -0.0638 -0.0314 -0.0549 -0.0367   \n",
      "2023-10-31 00:00:00-04:00 -0.0340 -0.0998  0.0221  0.0067  0.0351 -0.0476   \n",
      "2023-11-30 00:00:00-05:00  0.1224 -0.0205  0.0941  0.1360  0.0233  0.0510   \n",
      "2023-12-31 00:00:00-05:00  0.0898 -0.0269  0.0143 -0.0227 -0.0455  0.0134   \n",
      "\n",
      "                               HD    COST  \n",
      "Date                                       \n",
      "2023-08-31 00:00:00-04:00 -0.0043 -0.0185  \n",
      "2023-09-30 00:00:00-04:00 -0.0852  0.0285  \n",
      "2023-10-31 00:00:00-04:00 -0.0578 -0.0222  \n",
      "2023-11-30 00:00:00-05:00  0.1086  0.0749  \n",
      "2023-12-31 00:00:00-05:00  0.1055  0.1389  \n",
      "\n",
      "2. Testing Portfolio Optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\calvi\\Repositories\\NivlacSignals\\CS470_Project\\ml_trading_strategy\\strategy\\PortfolioStrategy.py:90: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = data['Close'].resample('M').last().pct_change()\n",
      "c:\\Users\\calvi\\Repositories\\NivlacSignals\\CS470_Project\\ml_trading_strategy\\strategy\\PortfolioStrategy.py:94: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_volumes = data['Volume'].resample('M').mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:23:24 - DataPipeline - INFO - Filtered universe contains 4 symbols\n",
      "Number of signals - Longs: 0, Shorts: 0\n",
      "20:23:24 - DataPipeline - ERROR - Error optimizing portfolio: Insufficient symbols for optimization\n",
      "Optimization error: Error optimizing portfolio: Insufficient symbols for optimization\n",
      "\n",
      "3. Testing Portfolio Rebalancing...\n",
      "20:23:24 - DataPipeline - WARNING - Insufficient positions for balanced portfolio\n",
      "\n",
      "New portfolio positions:\n",
      "\n",
      "4. Testing Performance Metrics...\n",
      "\n",
      "Portfolio metrics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\calvi\\Repositories\\NivlacSignals\\CS470_Project\\ml_trading_strategy\\strategy\\PortfolioStrategy.py:90: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_returns = data['Close'].resample('M').last().pct_change()\n",
      "c:\\Users\\calvi\\Repositories\\NivlacSignals\\CS470_Project\\ml_trading_strategy\\strategy\\PortfolioStrategy.py:94: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_volumes = data['Volume'].resample('M').mean()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m positions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(new_positions)\n\u001b[0;32m     74\u001b[0m colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m positions\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[1;32m---> 75\u001b[0m \u001b[43mpositions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPortfolio Positions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     77\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbols\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\calvi\\anaconda3\\envs\\ns_env\\Lib\\site-packages\\pandas\\plotting\\_core.py:1030\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   1028\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[1;32m-> 1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\calvi\\anaconda3\\envs\\ns_env\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[0;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 71\u001b[0m \u001b[43mplot_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32mc:\\Users\\calvi\\anaconda3\\envs\\ns_env\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:499\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_plot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfig\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_plot(fig)\n",
      "File \u001b[1;32mc:\\Users\\calvi\\anaconda3\\envs\\ns_env\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:698\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;66;03m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_empty:\n\u001b[1;32m--> 698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno numeric data to plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m numeric_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAH/CAYAAADXOLcaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh80lEQVR4nO3df2zV9b348VcLttXMVrxcyo9bx9Vd5zYVHEhXHTHedDaZYZc/btaLCxCi87pxjdrsTvAHnXOj3E0NyRVHZO665MYLG5neZZB6Xa9k2bU3ZPxINBcwjjGIWQvcXVqGG5X28/1jWfftKMgp9AXI45GcP/r2/T7nfcybhief86OsKIoiAAAAgFFVfrY3AAAAABcCAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAlKDvCf/OQnMWfOnJg8eXKUlZXFSy+99J5rNm3aFB//+MejsrIyPvShD8Xzzz8/gq0CAADA+avkAD9y5EhMmzYtVq1adUrzf/GLX8Ttt98et956a2zfvj3uv//+uOuuu+Lll18uebMAAABwvioriqIY8eKysnjxxRdj7ty5J5zz4IMPxoYNG+KNN94YHPu7v/u7OHToULS3t4/0oQEAAOC8Mna0H6CzszMaGxuHjDU1NcX9999/wjVHjx6No0ePDv48MDAQv/71r+PP/uzPoqysbLS2CgAAABERURRFHD58OCZPnhzl5Wfm49NGPcC7urqitrZ2yFhtbW309vbGb3/727j44ouPW9PW1haPPfbYaG8NAAAATmrfvn3xF3/xF2fkvkY9wEdi6dKl0dLSMvhzT09PXHHFFbFv376orq4+izsDAADgQtDb2xt1dXVx6aWXnrH7HPUAnzhxYnR3dw8Z6+7ujurq6mGvfkdEVFZWRmVl5XHj1dXVAhwAAIA0Z/Jt0KP+PeANDQ3R0dExZOyVV16JhoaG0X5oAAAAOGeUHOC/+c1vYvv27bF9+/aI+P3XjG3fvj327t0bEb9/+fiCBQsG599zzz2xe/fu+PKXvxw7d+6MZ555Jr73ve/FAw88cGaeAQAAAJwHSg7wn/3sZ3HDDTfEDTfcEBERLS0tccMNN8SyZcsiIuJXv/rVYIxHRPzlX/5lbNiwIV555ZWYNm1aPPnkk/Htb387mpqaztBTAAAAgHPfaX0PeJbe3t6oqamJnp4e7wEHAABg1I1Gh476e8ABAAAAAQ4AAAApBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQIIRBfiqVati6tSpUVVVFfX19bF58+aTzl+5cmV8+MMfjosvvjjq6urigQceiN/97ncj2jAAAACcj0oO8HXr1kVLS0u0trbG1q1bY9q0adHU1BT79+8fdv4LL7wQS5YsidbW1tixY0c899xzsW7dunjooYdOe/MAAABwvig5wJ966qn4/Oc/H4sWLYqPfvSjsXr16rjkkkviO9/5zrDzX3vttbj55pvjjjvuiKlTp8Ztt90W8+bNe8+r5gAAAPB+UlKA9/X1xZYtW6KxsfGPd1BeHo2NjdHZ2Tnsmptuuim2bNkyGNy7d++OjRs3xqc//enT2DYAAACcX8aWMvngwYPR398ftbW1Q8Zra2tj586dw66544474uDBg/HJT34yiqKIY8eOxT333HPSl6AfPXo0jh49Ovhzb29vKdsEAACAc86ofwr6pk2bYvny5fHMM8/E1q1b4wc/+EFs2LAhHn/88ROuaWtri5qamsFbXV3daG8TAAAARlVZURTFqU7u6+uLSy65JNavXx9z584dHF+4cGEcOnQo/v3f//24NbNnz45PfOIT8c1vfnNw7F//9V/j7rvvjt/85jdRXn78vwEMdwW8rq4uenp6orq6+lS3CwAAACPS29sbNTU1Z7RDS7oCXlFRETNmzIiOjo7BsYGBgejo6IiGhoZh17zzzjvHRfaYMWMiIuJE7V9ZWRnV1dVDbgAAAHA+K+k94BERLS0tsXDhwpg5c2bMmjUrVq5cGUeOHIlFixZFRMSCBQtiypQp0dbWFhERc+bMiaeeeipuuOGGqK+vj7feeiseffTRmDNnzmCIAwAAwPtdyQHe3NwcBw4ciGXLlkVXV1dMnz492tvbBz+Ybe/evUOueD/yyCNRVlYWjzzySLz99tvx53/+5zFnzpz4+te/fuaeBQAAAJzjSnoP+NkyGq+9BwAAgBM56+8BBwAAAEZGgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQIIRBfiqVati6tSpUVVVFfX19bF58+aTzj906FAsXrw4Jk2aFJWVlXH11VfHxo0bR7RhAAAAOB+NLXXBunXroqWlJVavXh319fWxcuXKaGpqil27dsWECROOm9/X1xef+tSnYsKECbF+/fqYMmVK/PKXv4zLLrvsTOwfAAAAzgtlRVEUpSyor6+PG2+8MZ5++umIiBgYGIi6urq49957Y8mSJcfNX716dXzzm9+MnTt3xkUXXTSiTfb29kZNTU309PREdXX1iO4DAAAATtVodGhJL0Hv6+uLLVu2RGNj4x/voLw8Ghsbo7Ozc9g1P/zhD6OhoSEWL14ctbW1ce2118by5cujv7//hI9z9OjR6O3tHXIDAACA81lJAX7w4MHo7++P2traIeO1tbXR1dU17Jrdu3fH+vXro7+/PzZu3BiPPvpoPPnkk/G1r33thI/T1tYWNTU1g7e6urpStgkAAADnnFH/FPSBgYGYMGFCPPvsszFjxoxobm6Ohx9+OFavXn3CNUuXLo2enp7B2759+0Z7mwAAADCqSvoQtvHjx8eYMWOiu7t7yHh3d3dMnDhx2DWTJk2Kiy66KMaMGTM49pGPfCS6urqir68vKioqjltTWVkZlZWVpWwNAAAAzmklXQGvqKiIGTNmREdHx+DYwMBAdHR0RENDw7Brbr755njrrbdiYGBgcOzNN9+MSZMmDRvfAAAA8H5U8kvQW1paYs2aNfHd7343duzYEV/4whfiyJEjsWjRooiIWLBgQSxdunRw/he+8IX49a9/Hffdd1+8+eabsWHDhli+fHksXrz4zD0LAAAAOMeV/D3gzc3NceDAgVi2bFl0dXXF9OnTo729ffCD2fbu3Rvl5X/s+rq6unj55ZfjgQceiOuvvz6mTJkS9913Xzz44INn7lkAAADAOa7k7wE/G3wPOAAAAJnO+veAAwAAACMjwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASDCiAF+1alVMnTo1qqqqor6+PjZv3nxK69auXRtlZWUxd+7ckTwsAAAAnLdKDvB169ZFS0tLtLa2xtatW2PatGnR1NQU+/fvP+m6PXv2xJe+9KWYPXv2iDcLAAAA56uSA/ypp56Kz3/+87Fo0aL46Ec/GqtXr45LLrkkvvOd75xwTX9/f3zuc5+Lxx57LK688srT2jAAAACcj0oK8L6+vtiyZUs0Njb+8Q7Ky6OxsTE6OztPuO6rX/1qTJgwIe68885TepyjR49Gb2/vkBsAAACcz0oK8IMHD0Z/f3/U1tYOGa+trY2urq5h1/z0pz+N5557LtasWXPKj9PW1hY1NTWDt7q6ulK2CQAAAOecUf0U9MOHD8f8+fNjzZo1MX78+FNet3Tp0ujp6Rm87du3bxR3CQAAAKNvbCmTx48fH2PGjInu7u4h493d3TFx4sTj5v/85z+PPXv2xJw5cwbHBgYGfv/AY8fGrl274qqrrjpuXWVlZVRWVpayNQAAADinlXQFvKKiImbMmBEdHR2DYwMDA9HR0RENDQ3Hzb/mmmvi9ddfj+3btw/ePvOZz8Stt94a27dv99JyAAAALhglXQGPiGhpaYmFCxfGzJkzY9asWbFy5co4cuRILFq0KCIiFixYEFOmTIm2traoqqqKa6+9dsj6yy67LCLiuHEAAAB4Pys5wJubm+PAgQOxbNmy6OrqiunTp0d7e/vgB7Pt3bs3ystH9a3lAAAAcN4pK4qiONubeC+9vb1RU1MTPT09UV1dfba3AwAAwPvcaHSoS9UAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkECAAwAAQAIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAECCEQX4qlWrYurUqVFVVRX19fWxefPmE85ds2ZNzJ49O8aNGxfjxo2LxsbGk84HAACA96OSA3zdunXR0tISra2tsXXr1pg2bVo0NTXF/v37h52/adOmmDdvXrz66qvR2dkZdXV1cdttt8Xbb7992psHAACA80VZURRFKQvq6+vjxhtvjKeffjoiIgYGBqKuri7uvffeWLJkyXuu7+/vj3HjxsXTTz8dCxYsOKXH7O3tjZqamujp6Ynq6upStgsAAAAlG40OLekKeF9fX2zZsiUaGxv/eAfl5dHY2BidnZ2ndB/vvPNOvPvuu3H55ZefcM7Ro0ejt7d3yA0AAADOZyUF+MGDB6O/vz9qa2uHjNfW1kZXV9cp3ceDDz4YkydPHhLxf6qtrS1qamoGb3V1daVsEwAAAM45qZ+CvmLFili7dm28+OKLUVVVdcJ5S5cujZ6ensHbvn37EncJAAAAZ97YUiaPHz8+xowZE93d3UPGu7u7Y+LEiSdd+8QTT8SKFSvixz/+cVx//fUnnVtZWRmVlZWlbA0AAADOaSVdAa+oqIgZM2ZER0fH4NjAwEB0dHREQ0PDCdd94xvfiMcffzza29tj5syZI98tAAAAnKdKugIeEdHS0hILFy6MmTNnxqxZs2LlypVx5MiRWLRoUURELFiwIKZMmRJtbW0REfFP//RPsWzZsnjhhRdi6tSpg+8V/8AHPhAf+MAHzuBTAQAAgHNXyQHe3NwcBw4ciGXLlkVXV1dMnz492tvbBz+Ybe/evVFe/scL69/61reir68v/vZv/3bI/bS2tsZXvvKV09s9AAAAnCdK/h7ws8H3gAMAAJDprH8POAAAADAyAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQCHAAAABIIcAAAAEggwAEAACCBAAcAAIAEAhwAAAASCHAAAABIIMABAAAggQAHAACABAIcAAAAEghwAAAASCDAAQAAIIEABwAAgAQjCvBVq1bF1KlTo6qqKurr62Pz5s0nnf/9738/rrnmmqiqqorrrrsuNm7cOKLNAgAAwPmq5ABft25dtLS0RGtra2zdujWmTZsWTU1NsX///mHnv/baazFv3ry48847Y9u2bTF37tyYO3duvPHGG6e9eQAAADhflBVFUZSyoL6+Pm688cZ4+umnIyJiYGAg6urq4t57740lS5YcN7+5uTmOHDkSP/rRjwbHPvGJT8T06dNj9erVp/SYvb29UVNTEz09PVFdXV3KdgEAAKBko9GhY0uZ3NfXF1u2bImlS5cOjpWXl0djY2N0dnYOu6azszNaWlqGjDU1NcVLL710wsc5evRoHD16dPDnnp6eiPj9/wAAAAAYbX/ozxKvWZ9USQF+8ODB6O/vj9ra2iHjtbW1sXPnzmHXdHV1DTu/q6vrhI/T1tYWjz322HHjdXV1pWwXAAAATsv//u//Rk1NzRm5r5ICPMvSpUuHXDU/dOhQfPCDH4y9e/eesScO55re3t6oq6uLffv2easF71vOORcC55wLgXPOhaCnpyeuuOKKuPzyy8/YfZYU4OPHj48xY8ZEd3f3kPHu7u6YOHHisGsmTpxY0vyIiMrKyqisrDxuvKamxh9w3veqq6udc973nHMuBM45FwLnnAtBefmZ+/buku6poqIiZsyYER0dHYNjAwMD0dHREQ0NDcOuaWhoGDI/IuKVV1454XwAAAB4Pyr5JegtLS2xcOHCmDlzZsyaNStWrlwZR44ciUWLFkVExIIFC2LKlCnR1tYWERH33Xdf3HLLLfHkk0/G7bffHmvXro2f/exn8eyzz57ZZwIAAADnsJIDvLm5OQ4cOBDLli2Lrq6umD59erS3tw9+0NrevXuHXKK/6aab4oUXXohHHnkkHnroofirv/qreOmll+Laa6895cesrKyM1tbWYV+WDu8XzjkXAuecC4FzzoXAOedCMBrnvOTvAQcAAABKd+beTQ4AAACckAAHAACABAIcAAAAEghwAAAASHDOBPiqVati6tSpUVVVFfX19bF58+aTzv/+978f11xzTVRVVcV1110XGzduTNopjFwp53zNmjUxe/bsGDduXIwbNy4aGxvf888FnAtK/X3+B2vXro2ysrKYO3fu6G4QzoBSz/mhQ4di8eLFMWnSpKisrIyrr77a310455V6zleuXBkf/vCH4+KLL466urp44IEH4ne/+13SbqE0P/nJT2LOnDkxefLkKCsri5deeuk912zatCk+/vGPR2VlZXzoQx+K559/vuTHPScCfN26ddHS0hKtra2xdevWmDZtWjQ1NcX+/fuHnf/aa6/FvHnz4s4774xt27bF3LlzY+7cufHGG28k7xxOXannfNOmTTFv3rx49dVXo7OzM+rq6uK2226Lt99+O3nncOpKPed/sGfPnvjSl74Us2fPTtopjFyp57yvry8+9alPxZ49e2L9+vWxa9euWLNmTUyZMiV553DqSj3nL7zwQixZsiRaW1tjx44d8dxzz8W6devioYceSt45nJojR47EtGnTYtWqVac0/xe/+EXcfvvtceutt8b27dvj/vvvj7vuuitefvnl0h64OAfMmjWrWLx48eDP/f39xeTJk4u2trZh53/2s58tbr/99iFj9fX1xd///d+P6j7hdJR6zv/UsWPHiksvvbT47ne/O1pbhNM2knN+7Nix4qabbiq+/e1vFwsXLiz+5m/+JmGnMHKlnvNvfetbxZVXXln09fVlbRFOW6nnfPHixcVf//VfDxlraWkpbr755lHdJ5wJEVG8+OKLJ53z5S9/ufjYxz42ZKy5ubloamoq6bHO+hXwvr6+2LJlSzQ2Ng6OlZeXR2NjY3R2dg67prOzc8j8iIimpqYTzoezbSTn/E+988478e6778bll18+WtuE0zLSc/7Vr341JkyYEHfeeWfGNuG0jOSc//CHP4yGhoZYvHhx1NbWxrXXXhvLly+P/v7+rG1DSUZyzm+66abYsmXL4MvUd+/eHRs3boxPf/rTKXuG0XamGnTsmdzUSBw8eDD6+/ujtrZ2yHhtbW3s3Llz2DVdXV3Dzu/q6hq1fcLpGMk5/1MPPvhgTJ48+bg/+HCuGMk5/+lPfxrPPfdcbN++PWGHcPpGcs53794d//mf/xmf+9znYuPGjfHWW2/FF7/4xXj33XejtbU1Y9tQkpGc8zvuuCMOHjwYn/zkJ6Moijh27Fjcc889XoLO+8aJGrS3tzd++9vfxsUXX3xK93PWr4AD723FihWxdu3aePHFF6OqqupsbwfOiMOHD8f8+fNjzZo1MX78+LO9HRg1AwMDMWHChHj22WdjxowZ0dzcHA8//HCsXr36bG8NzphNmzbF8uXL45lnnomtW7fGD37wg9iwYUM8/vjjZ3trcE4561fAx48fH2PGjInu7u4h493d3TFx4sRh10ycOLGk+XC2jeSc/8ETTzwRK1asiB//+Mdx/fXXj+Y24bSUes5//vOfx549e2LOnDmDYwMDAxERMXbs2Ni1a1dcddVVo7tpKNFIfp9PmjQpLrroohgzZszg2Ec+8pHo6uqKvr6+qKioGNU9Q6lGcs4fffTRmD9/ftx1110REXHdddfFkSNH4u67746HH344ystd9+P8dqIGra6uPuWr3xHnwBXwioqKmDFjRnR0dAyODQwMREdHRzQ0NAy7pqGhYcj8iIhXXnnlhPPhbBvJOY+I+MY3vhGPP/54tLe3x8yZMzO2CiNW6jm/5ppr4vXXX4/t27cP3j7zmc8MfrpoXV1d5vbhlIzk9/nNN98cb7311uA/MEVEvPnmmzFp0iTxzTlpJOf8nXfeOS6y//CPTr//jCs4v52xBi3t8+FGx9q1a4vKysri+eefL/7nf/6nuPvuu4vLLrus6OrqKoqiKObPn18sWbJkcP5//dd/FWPHji2eeOKJYseOHUVra2tx0UUXFa+//vrZegrwnko95ytWrCgqKiqK9evXF7/61a8Gb4cPHz5bTwHeU6nn/E/5FHTOB6We87179xaXXnpp8Q//8A/Frl27ih/96EfFhAkTiq997Wtn6ynAeyr1nLe2thaXXnpp8W//9m/F7t27i//4j/8orrrqquKzn/3s2XoKcFKHDx8utm3bVmzbtq2IiOKpp54qtm3bVvzyl78siqIolixZUsyfP39w/u7du4tLLrmk+Md//Mdix44dxapVq4oxY8YU7e3tJT3uORHgRVEU//zP/1xcccUVRUVFRTFr1qziv//7vwf/2y233FIsXLhwyPzvfe97xdVXX11UVFQUH/vYx4oNGzYk7xhKV8o5/+AHP1hExHG31tbW/I1DCUr9ff7/E+CcL0o956+99lpRX19fVFZWFldeeWXx9a9/vTh27FjyrqE0pZzzd999t/jKV75SXHXVVUVVVVVRV1dXfPGLXyz+7//+L3/jcApeffXVYf+u/YdzvXDhwuKWW245bs306dOLioqK4sorryz+5V/+peTHLSsKrwkBAACA0XbW3wMOAAAAFwIBDgAAAAkEOAAAACQQ4AAAAJBAgAMAAEACAQ4AAAAJBDgAAAAkEOAAAACQQIADAABAAgEOAAAACQQ4AAAAJBDgAAAAkOD/Ac7nRNdHzOW8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add this after your existing code\n",
    "\n",
    "from strategy.PortfolioStrategy import PortfolioStrategy\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize the portfolio strategy\n",
    "strategy = PortfolioStrategy(\n",
    "    data_pipeline=pipeline,\n",
    "    initial_capital=1_000_000\n",
    ")\n",
    "\n",
    "print(\"\\nTesting Portfolio Strategy\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 1. Test monthly metrics calculation\n",
    "print(\"\\n1. Testing Monthly Metrics Calculation...\")\n",
    "strategy.update_monthly_metrics()\n",
    "print(f\"Monthly returns shape: {strategy.monthly_returns.shape}\")\n",
    "print(f\"Monthly volumes shape: {strategy.monthly_volumes.shape}\")\n",
    "\n",
    "# Print sample of monthly returns\n",
    "print(\"\\nSample of monthly returns:\")\n",
    "print(strategy.monthly_returns.tail().round(4))\n",
    "\n",
    "# 2. Test portfolio optimization\n",
    "print(\"\\n2. Testing Portfolio Optimization...\")\n",
    "latest_signals = mean_reversion.generate_signals()\n",
    "print(f\"Number of signals - Longs: {len(latest_signals.longs)}, Shorts: {len(latest_signals.shorts)}\")\n",
    "\n",
    "try:\n",
    "    optimal_weights = strategy.optimize_portfolio(\n",
    "        latest_signals,\n",
    "        strategy.monthly_returns\n",
    "    )\n",
    "    print(\"\\nOptimal portfolio weights:\")\n",
    "    for symbol, weight in sorted(optimal_weights.items(), key=lambda x: abs(x[1]), reverse=True):\n",
    "        print(f\"{symbol}: {weight:.4f}\")\n",
    "    \n",
    "    # Calculate total long and short exposure\n",
    "    total_long = sum(w for w in optimal_weights.values() if w > 0)\n",
    "    total_short = sum(w for w in optimal_weights.values() if w < 0)\n",
    "    print(f\"\\nTotal long exposure: {total_long:.4f}\")\n",
    "    print(f\"Total short exposure: {total_short:.4f}\")\n",
    "    print(f\"Net exposure: {total_long + total_short:.4f}\")\n",
    "    print(f\"Gross exposure: {total_long - total_short:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Optimization error: {e}\")\n",
    "\n",
    "# 3. Test portfolio rebalancing\n",
    "print(\"\\n3. Testing Portfolio Rebalancing...\")\n",
    "current_date = pd.Timestamp('2023-12-31')\n",
    "try:\n",
    "    new_positions = strategy.rebalance_portfolio(latest_signals, current_date)\n",
    "    print(\"\\nNew portfolio positions:\")\n",
    "    for symbol, pos in sorted(new_positions.items(), key=lambda x: abs(x[1]), reverse=True):\n",
    "        print(f\"{symbol}: {pos:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Rebalancing error: {e}\")\n",
    "\n",
    "# 4. Test performance metrics\n",
    "print(\"\\n4. Testing Performance Metrics...\")\n",
    "metrics = strategy.calculate_portfolio_metrics()\n",
    "print(\"\\nPortfolio metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# 5. Visualize Portfolio Allocation\n",
    "plt.figure(figsize=(12, 6))\n",
    "positions = pd.Series(new_positions)\n",
    "colors = ['green' if x > 0 else 'red' for x in positions.values]\n",
    "positions.plot(kind='bar', color=colors)\n",
    "plt.title('Portfolio Positions')\n",
    "plt.xlabel('Symbols')\n",
    "plt.ylabel('Position Size')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Visualize Monthly Returns Distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "strategy.monthly_returns.mean().hist(bins=20)\n",
    "plt.title('Distribution of Monthly Returns')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Print Strategy Settings\n",
    "print(\"\\n5. Strategy Settings:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Rebalance frequency: {strategy.rebalance_days} days\")\n",
    "print(f\"Max position size: {strategy.max_position_size:.2%}\")\n",
    "print(f\"Min positions per side: {strategy.min_positions}\")\n",
    "print(f\"Target leverage: {strategy.target_leverage:.2f}\")\n",
    "print(f\"Risk-free rate: {strategy.risk_free_rate:.2%}\")\n",
    "\n",
    "# 8. Risk Analysis\n",
    "print(\"\\n6. Risk Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "if len(strategy.monthly_returns) > 0:\n",
    "    returns_matrix = strategy.monthly_returns.fillna(0)\n",
    "    correlation_matrix = returns_matrix.corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Asset Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and print risk metrics\n",
    "    volatility = returns_matrix.std() * np.sqrt(12)\n",
    "    print(\"\\nAnnualized Volatility by Asset:\")\n",
    "    print(volatility.sort_values(ascending=False).round(4))\n",
    "\n",
    "# 9. Position Limits Check\n",
    "print(\"\\n7. Position Limits Check:\")\n",
    "print(\"-\" * 50)\n",
    "if new_positions:\n",
    "    max_position = max(abs(pd.Series(new_positions)))\n",
    "    print(f\"Maximum absolute position size: {max_position:.2%}\")\n",
    "    print(f\"Position size limit: {strategy.max_position_size:.2%}\")\n",
    "    print(\"Position limit check:\", \"PASSED\" if max_position <= strategy.max_position_size else \"FAILED\")\n",
    "\n",
    "# Save results to a report\n",
    "report = pd.DataFrame({\n",
    "    'Metric': list(metrics.keys()),\n",
    "    'Value': list(metrics.values())\n",
    "})\n",
    "\n",
    "print(\"\\n8. Saving results...\")\n",
    "report.to_csv('strategy_test_results.csv', index=False)\n",
    "print(\"Results saved to 'strategy_test_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ns_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
