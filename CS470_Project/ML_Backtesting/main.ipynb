{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Backtest import Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error generating signals: 'NoneType' object has no attribute 'keys'\n",
      "Error updating factor pipeline: 'NoneType' object has no attribute 'keys'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 134\u001b[0m\n\u001b[0;32m    126\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m FactorPipeline(\n\u001b[0;32m    127\u001b[0m     ml_model\u001b[38;5;241m=\u001b[39mml_model,\n\u001b[0;32m    128\u001b[0m     mean_reversion\u001b[38;5;241m=\u001b[39mmean_reversion,\n\u001b[0;32m    129\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    130\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Update pipeline\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# ## 6. Analyze Results\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Get signal metrics\u001b[39;00m\n\u001b[0;32m    141\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mget_signal_metrics()\n",
      "File \u001b[1;32mc:\\Users\\calvi\\Repositories\\NivlacSignals\\CS470_Project\\ML_Backtesting\\FactorPipeline.py:300\u001b[0m, in \u001b[0;36mFactorPipeline.update\u001b[1;34m(self, latest_data)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03mUpdate signals and positions with latest data\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# Generate new signals\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m# Update rankings\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_securities()\n",
      "File \u001b[1;32mc:\\Users\\calvi\\Repositories\\NivlacSignals\\CS470_Project\\ML_Backtesting\\FactorPipeline.py:94\u001b[0m, in \u001b[0;36mFactorPipeline.generate_signals\u001b[1;34m(self, latest_data)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Get ML model predictions\u001b[39;00m\n\u001b[0;32m     93\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_features()\n\u001b[1;32m---> 94\u001b[0m ml_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mml_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m ml_signals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(ml_predictions, index\u001b[38;5;241m=\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Get mean reversion signals\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 31\u001b[0m, in \u001b[0;36mMockMLModel.predict\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Generate predictions between -1 and 1\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())  \u001b[38;5;66;03m# Get symbols from features dict\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(symbols))\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(predictions, index\u001b[38;5;241m=\u001b[39msymbols)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # FactorPipeline Testing Notebook\n",
    "# This notebook tests the functionality of our FactorPipeline implementation.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Setup and Imports\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List\n",
    "\n",
    "# Import our FactorPipeline class\n",
    "from FactorPipeline import FactorPipeline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Create Mock Components\n",
    "\n",
    "# %%\n",
    "class MockMLModel:\n",
    "    \"\"\"Mock ML model for testing\"\"\"\n",
    "    def predict(self, features: pd.DataFrame) -> pd.Series:\n",
    "        # Generate predictions between -1 and 1\n",
    "        symbols = list(features.keys())  # Get symbols from features dict\n",
    "        predictions = np.random.uniform(-1, 1, len(symbols))\n",
    "        return pd.Series(predictions, index=symbols)\n",
    "        \n",
    "    def update(self, new_data):\n",
    "        pass  # Mock update method\n",
    "\n",
    "class MockMeanReversion:\n",
    "    \"\"\"Mock mean reversion analyzer for testing\"\"\"\n",
    "    def generate_signals(self, data: Dict[str, pd.DataFrame]):\n",
    "        # Generate random z-scores\n",
    "        symbols = list(data.keys())\n",
    "        scores = np.random.normal(0, 1, len(symbols))\n",
    "        signal_strength = pd.Series(scores, index=symbols)\n",
    "        \n",
    "        # Create mock signal object\n",
    "        class Signals:\n",
    "            def __init__(self, strength):\n",
    "                self.signal_strength = strength\n",
    "                \n",
    "        return Signals(signal_strength)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Generate Test Data\n",
    "\n",
    "# %%\n",
    "def generate_test_data(\n",
    "    symbols: List[str],\n",
    "    days: int = 100,\n",
    "    start_date: datetime = datetime(2023, 1, 1)\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Generate realistic test data for multiple symbols\"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        # Generate dates\n",
    "        dates = [start_date + timedelta(days=x) for x in range(days)]\n",
    "        \n",
    "        # Generate price data with trend and volatility\n",
    "        returns = np.random.normal(0.0005, 0.02, days)  # Daily returns\n",
    "        prices = 100 * np.exp(np.cumsum(returns))  # Log-normal prices\n",
    "        \n",
    "        # Generate volume data\n",
    "        volume = np.random.lognormal(15, 0.5, days)  # Log-normal volumes\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'Open': prices * (1 + np.random.normal(0, 0.002, days)),\n",
    "            'High': prices * (1 + np.abs(np.random.normal(0, 0.004, days))),\n",
    "            'Low': prices * (1 - np.abs(np.random.normal(0, 0.004, days))),\n",
    "            'Close': prices,\n",
    "            'Volume': volume.astype(int)\n",
    "        }, index=dates)\n",
    "        \n",
    "        data[symbol] = df\n",
    "    \n",
    "    return data\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Load Configuration\n",
    "\n",
    "# %%\n",
    "# Load or create config\n",
    "config = {\n",
    "    'factor_pipeline': {\n",
    "        'model_weight': 0.5,\n",
    "        'mean_reversion_weight': 0.5,\n",
    "        'min_score_threshold': 0.1,\n",
    "        'confidence_threshold': 0.6,\n",
    "        'prediction_frequency': 1\n",
    "    },\n",
    "    'portfolio_strategy': {\n",
    "        'max_position_size': 0.10,\n",
    "        'min_positions': 3,\n",
    "        'target_leverage': 1.0,\n",
    "        'risk_free_rate': 0.02,\n",
    "        'max_sector_exposure': 0.30,\n",
    "    }\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Initialize and Test Pipeline\n",
    "\n",
    "# %%\n",
    "# Test symbols\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'JPM', 'V', 'WMT']\n",
    "\n",
    "# Generate test data\n",
    "data = generate_test_data(symbols)\n",
    "\n",
    "# Initialize pipeline components\n",
    "ml_model = MockMLModel()\n",
    "mean_reversion = MockMeanReversion()\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = FactorPipeline(\n",
    "    ml_model=ml_model,\n",
    "    mean_reversion=mean_reversion,\n",
    "    data=data,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Update pipeline\n",
    "pipeline.update()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Analyze Results\n",
    "\n",
    "# %%\n",
    "# Get signal metrics\n",
    "metrics_df = pipeline.get_signal_metrics()\n",
    "print(\"\\nSignal Metrics:\")\n",
    "display(metrics_df)\n",
    "\n",
    "# Get current positions\n",
    "longs, shorts = pipeline.get_current_positions()\n",
    "print(\"\\nLong Positions:\")\n",
    "for symbol, size in longs.items():\n",
    "    print(f\"{symbol}: {size:.2%}\")\n",
    "    \n",
    "print(\"\\nShort Positions:\")\n",
    "for symbol, size in shorts.items():\n",
    "    print(f\"{symbol}: {size:.2%}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Visualize Results\n",
    "\n",
    "# %%\n",
    "# Plot signal distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# ML Signals\n",
    "plt.subplot(131)\n",
    "sns.histplot(metrics_df['ml_signal'], bins=20)\n",
    "plt.title('ML Signal Distribution')\n",
    "plt.xlabel('Signal Value')\n",
    "\n",
    "# Mean Reversion Signals\n",
    "plt.subplot(132)\n",
    "sns.histplot(metrics_df['mean_rev_signal'], bins=20)\n",
    "plt.title('Mean Reversion Signal Distribution')\n",
    "plt.xlabel('Signal Value')\n",
    "\n",
    "# Combined Signals\n",
    "plt.subplot(133)\n",
    "sns.histplot(metrics_df['combined_signal'], bins=20)\n",
    "plt.title('Combined Signal Distribution')\n",
    "plt.xlabel('Signal Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Plot position allocations\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Combine long and short positions\n",
    "all_positions = pd.Series({**longs, **{k: -v for k, v in shorts.items()}})\n",
    "colors = ['g' if v > 0 else 'r' for v in all_positions]\n",
    "\n",
    "plt.bar(all_positions.index, all_positions.values, color=colors)\n",
    "plt.title('Position Allocations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Position Size')\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Test Signal Updates\n",
    "\n",
    "# %%\n",
    "def test_signal_stability():\n",
    "    \"\"\"Test stability of signals over multiple updates\"\"\"\n",
    "    signal_history = []\n",
    "    position_history = []\n",
    "    \n",
    "    # Run multiple updates\n",
    "    for _ in range(5):\n",
    "        pipeline.update()\n",
    "        metrics = pipeline.get_signal_metrics()\n",
    "        longs, shorts = pipeline.get_current_positions()\n",
    "        \n",
    "        signal_history.append(metrics['combined_signal'].to_dict())\n",
    "        position_history.append({\n",
    "            'longs': list(longs.keys()),\n",
    "            'shorts': list(shorts.keys())\n",
    "        })\n",
    "    \n",
    "    return signal_history, position_history\n",
    "\n",
    "# Run stability test\n",
    "signal_history, position_history = test_signal_stability()\n",
    "\n",
    "# Print position changes\n",
    "print(\"Position Changes Over Updates:\")\n",
    "for i, pos in enumerate(position_history):\n",
    "    print(f\"\\nUpdate {i+1}:\")\n",
    "    print(f\"Longs: {pos['longs']}\")\n",
    "    print(f\"Shorts: {pos['shorts']}\")\n",
    "\n",
    "# Plot signal stability\n",
    "signals_df = pd.DataFrame(signal_history)\n",
    "plt.figure(figsize=(12, 6))\n",
    "signals_df.plot(marker='o')\n",
    "plt.title('Signal Stability Over Updates')\n",
    "plt.xlabel('Update')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Test Risk Filters\n",
    "\n",
    "# %%\n",
    "def test_risk_filters():\n",
    "    \"\"\"Test the impact of risk filters\"\"\"\n",
    "    # Get pre-filter signals\n",
    "    pre_filter = pipeline.current_signals.combined_signals\n",
    "    \n",
    "    # Get post-filter scores\n",
    "    post_filter = pipeline.current_rankings.filtered_scores\n",
    "    \n",
    "    # Compare\n",
    "    comparison = pd.DataFrame({\n",
    "        'pre_filter': pre_filter,\n",
    "        'post_filter': post_filter\n",
    "    })\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "# Run risk filter test\n",
    "filter_comparison = test_risk_filters()\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filter_comparison.index, filter_comparison['pre_filter'], \n",
    "           label='Pre-Filter', alpha=0.6)\n",
    "plt.scatter(filter_comparison.index, filter_comparison['post_filter'], \n",
    "           label='Post-Filter', alpha=0.6)\n",
    "plt.title('Impact of Risk Filters')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Validation Checks\n",
    "\n",
    "# %%\n",
    "def run_validation_checks():\n",
    "    \"\"\"Run validation checks on pipeline outputs\"\"\"\n",
    "    checks = {\n",
    "        'Position Sizes Sum to 1': abs(sum(longs.values()) - 1.0) < 0.0001 and \n",
    "                                  abs(sum(shorts.values()) - 1.0) < 0.0001,\n",
    "        'No Position Size Exceeds Max': all(v <= config['portfolio_strategy']['max_position_size'] \n",
    "                                          for v in list(longs.values()) + list(shorts.values())),\n",
    "        'Minimum Positions Met': len(longs) >= config['portfolio_strategy']['min_positions'] and \n",
    "                               len(shorts) >= config['portfolio_strategy']['min_positions'],\n",
    "        'No Overlapping Positions': len(set(longs.keys()) & set(shorts.keys())) == 0\n",
    "    }\n",
    "    \n",
    "    return pd.Series(checks)\n",
    "\n",
    "# Run validation checks\n",
    "validation_results = run_validation_checks()\n",
    "print(\"\\nValidation Checks:\")\n",
    "display(validation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ns_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
