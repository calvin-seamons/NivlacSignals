{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Backtest import Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 14:27:31,262 - __main__ - INFO - Starting backtest test\n",
      "2024-12-18 14:27:31,262 - __main__ - INFO - Setting up directories...\n",
      "2024-12-18 14:27:31,264 - __main__ - INFO - Testing with directories:\n",
      "2024-12-18 14:27:31,264 - __main__ - INFO - base_dir: /Users/calvinseamons/Repositories/NivlacSignals/CS470_Project/ML_Backtesting\n",
      "2024-12-18 14:27:31,264 - __main__ - INFO - data_dir: /Users/calvinseamons/Repositories/NivlacSignals/CS470_Project/ML_Backtesting/data\n",
      "2024-12-18 14:27:31,265 - __main__ - INFO - db_dir: /Users/calvinseamons/Repositories/NivlacSignals/CS470_Project/ML_Backtesting/data/db\n",
      "2024-12-18 14:27:31,265 - __main__ - INFO - cache_dir: /Users/calvinseamons/Repositories/NivlacSignals/CS470_Project/ML_Backtesting/data/cache\n",
      "2024-12-18 14:27:31,265 - __main__ - INFO - config_path: /Users/calvinseamons/Repositories/NivlacSignals/CS470_Project/ML_Backtesting/config.yaml\n",
      "2024-12-18 14:27:31,266 - __main__ - INFO - Initializing Backtest class...\n",
      "2024-12-18 14:27:31,266 - __main__ - INFO - Fetching historical data for symbols: ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META']\n",
      "2024-12-18 14:27:31,267 - Backtest - INFO - Starting fetch_historical_data for 5 symbols\n",
      "2024-12-18 14:27:31,269 - Backtest - INFO - Date range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "2024-12-18 14:27:31,269 - Backtest - INFO - Creating new BacktestDataManager instance\n",
      "2024-12-18 14:27:31,270 - Backtest - INFO - Calling data_manager.get_data\n",
      "2024-12-18 14:27:31,371 - Backtest - INFO - Retrieved data for 5 symbols\n",
      "2024-12-18 14:27:31,372 - Backtest - INFO - Retrieved 250 rows for MSFT\n",
      "2024-12-18 14:27:31,372 - Backtest - INFO - Retrieved 250 rows for AAPL\n",
      "2024-12-18 14:27:31,372 - Backtest - INFO - Retrieved 250 rows for GOOGL\n",
      "2024-12-18 14:27:31,373 - Backtest - INFO - Retrieved 250 rows for META\n",
      "2024-12-18 14:27:31,373 - Backtest - INFO - Retrieved 250 rows for AMZN\n",
      "2024-12-18 14:27:31,374 - __main__ - INFO - Retrieved data for 5 symbols\n",
      "2024-12-18 14:27:31,374 - __main__ - INFO - \n",
      "Summary for MSFT:\n",
      "2024-12-18 14:27:31,374 - __main__ - INFO - Date Range: 2023-01-03 00:00:00-05:00 to 2023-12-29 00:00:00-05:00\n",
      "2024-12-18 14:27:31,375 - __main__ - INFO - Number of trading days: 250\n",
      "2024-12-18 14:27:31,375 - __main__ - INFO - \n",
      "Price Statistics:\n",
      "2024-12-18 14:27:31,377 - __main__ - INFO - count    250.000000\n",
      "mean     310.412095\n",
      "std       41.211713\n",
      "min      218.720551\n",
      "25%      279.123070\n",
      "50%      321.078857\n",
      "75%      334.119759\n",
      "max      379.859497\n",
      "Name: Close, dtype: float64\n",
      "2024-12-18 14:27:31,379 - __main__ - INFO - \n",
      "Summary for AAPL:\n",
      "2024-12-18 14:27:31,379 - __main__ - INFO - Date Range: 2023-01-03 00:00:00-05:00 to 2023-12-29 00:00:00-05:00\n",
      "2024-12-18 14:27:31,379 - __main__ - INFO - Number of trading days: 250\n",
      "2024-12-18 14:27:31,380 - __main__ - INFO - \n",
      "Price Statistics:\n",
      "2024-12-18 14:27:31,381 - __main__ - INFO - count    250.000000\n",
      "mean     171.281995\n",
      "std       17.418788\n",
      "min      123.718979\n",
      "25%      160.670429\n",
      "50%      174.389793\n",
      "75%      186.265339\n",
      "max      197.144180\n",
      "Name: Close, dtype: float64\n",
      "2024-12-18 14:27:31,382 - __main__ - INFO - \n",
      "Summary for GOOGL:\n",
      "2024-12-18 14:27:31,383 - __main__ - INFO - Date Range: 2023-01-03 00:00:00-05:00 to 2023-12-29 00:00:00-05:00\n",
      "2024-12-18 14:27:31,383 - __main__ - INFO - Number of trading days: 250\n",
      "2024-12-18 14:27:31,384 - __main__ - INFO - \n",
      "Price Statistics:\n",
      "2024-12-18 14:27:31,386 - __main__ - INFO - count    250.000000\n",
      "mean     118.365635\n",
      "std       16.110085\n",
      "min       85.888649\n",
      "25%      104.274496\n",
      "50%      122.869587\n",
      "75%      131.936714\n",
      "max      141.008835\n",
      "Name: Close, dtype: float64\n",
      "2024-12-18 14:27:31,387 - __main__ - INFO - \n",
      "Summary for META:\n",
      "2024-12-18 14:27:31,388 - __main__ - INFO - Date Range: 2023-01-03 00:00:00-05:00 to 2023-12-29 00:00:00-05:00\n",
      "2024-12-18 14:27:31,388 - __main__ - INFO - Number of trading days: 250\n",
      "2024-12-18 14:27:31,389 - __main__ - INFO - \n",
      "Price Statistics:\n",
      "2024-12-18 14:27:31,391 - __main__ - INFO - count    250.000000\n",
      "mean     260.429458\n",
      "std       62.881574\n",
      "min      124.265312\n",
      "25%      209.121170\n",
      "50%      285.295197\n",
      "75%      310.531288\n",
      "max      356.956451\n",
      "Name: Close, dtype: float64\n",
      "2024-12-18 14:27:31,392 - __main__ - INFO - \n",
      "Summary for AMZN:\n",
      "2024-12-18 14:27:31,392 - __main__ - INFO - Date Range: 2023-01-03 00:00:00-05:00 to 2023-12-29 00:00:00-05:00\n",
      "2024-12-18 14:27:31,393 - __main__ - INFO - Number of trading days: 250\n",
      "2024-12-18 14:27:31,393 - __main__ - INFO - \n",
      "Price Statistics:\n",
      "2024-12-18 14:27:31,395 - __main__ - INFO - count    250.000000\n",
      "mean     121.372800\n",
      "std       18.900946\n",
      "min       83.120003\n",
      "25%      102.254999\n",
      "50%      126.830002\n",
      "75%      135.360001\n",
      "max      154.070007\n",
      "Name: Close, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting get_data ===\n",
      "Input symbols: ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META']\n",
      "Date range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "\n",
      "Validating symbols...\n",
      "\n",
      "=== Starting symbol validation ===\n",
      "Validating 5 symbols: ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META']\n",
      "\n",
      "Checking symbol: AAPL\n",
      "Database query result for AAPL: (1, '2023-01-03', '2023-12-29')\n",
      "Date range in DB: 2023-01-03 to 2023-12-29\n",
      "Adding AAPL to valid symbols - date range acceptable\n",
      "\n",
      "Checking symbol: GOOGL\n",
      "Database query result for GOOGL: (1, '2023-01-03', '2023-12-29')\n",
      "Date range in DB: 2023-01-03 to 2023-12-29\n",
      "Adding GOOGL to valid symbols - date range acceptable\n",
      "\n",
      "Checking symbol: MSFT\n",
      "Database query result for MSFT: (1, '2023-01-03', '2023-12-29')\n",
      "Date range in DB: 2023-01-03 to 2023-12-29\n",
      "Adding MSFT to valid symbols - date range acceptable\n",
      "\n",
      "Checking symbol: AMZN\n",
      "Database query result for AMZN: (1, '2023-01-03', '2023-12-29')\n",
      "Date range in DB: 2023-01-03 to 2023-12-29\n",
      "Adding AMZN to valid symbols - date range acceptable\n",
      "\n",
      "Checking symbol: META\n",
      "Database query result for META: (1, '2023-01-03', '2023-12-29')\n",
      "Date range in DB: 2023-01-03 to 2023-12-29\n",
      "Adding META to valid symbols - date range acceptable\n",
      "\n",
      "=== Completed symbol validation ===\n",
      "Found 5 valid symbols: ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META']\n",
      "Valid symbols after validation: ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META']\n",
      "\n",
      "Starting parallel processing...\n",
      "Created ThreadPoolExecutor with max_workers: 100\n",
      "Submitted 5 tasks to executor\n",
      "\n",
      "=== Downloading data for MSFT ===\n",
      "Date range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "Download attempt 1 for MSFT\n",
      "\n",
      "=== Downloading data for AAPL ===\n",
      "Date range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "Download attempt 1 for AAPL\n",
      "\n",
      "=== Downloading data for GOOGL ===\n",
      "Date range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "Download attempt 1 for GOOGL\n",
      "\n",
      "=== Downloading data for META ===\n",
      "Date range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "Download attempt 1 for META\n",
      "\n",
      "=== Downloading data for AMZN ===\n",
      "Date range: 2023-01-01 00:00:00 to 2024-01-01 00:00:00\n",
      "Download attempt 1 for AMZN\n",
      "Downloaded 250 rows of data for MSFT\n",
      "Sufficient data points (250) for MSFT\n",
      "Data validation successful for MSFT\n",
      "Downloaded 250 rows of data for AAPL\n",
      "Sufficient data points (250) for AAPL\n",
      "Data validation successful for AAPL\n",
      "Downloaded 250 rows of data for GOOGL\n",
      "Sufficient data points (250) for GOOGL\n",
      "Data validation successful for GOOGL\n",
      "Downloaded 250 rows of data for META\n",
      "Sufficient data points (250) for META\n",
      "Data validation successful for META\n",
      "Downloaded 250 rows of data for AMZN\n",
      "Sufficient data points (250) for AMZN\n",
      "Data validation successful for AMZN\n",
      "\n",
      "Processing result for symbol: MSFT\n",
      "Successfully retrieved data for MSFT, shape: (250, 7)\n",
      "\n",
      "Processing result for symbol: AAPL\n",
      "Successfully retrieved data for AAPL, shape: (250, 7)\n",
      "\n",
      "Processing result for symbol: GOOGL\n",
      "Successfully retrieved data for GOOGL, shape: (250, 7)\n",
      "\n",
      "Processing result for symbol: META\n",
      "Successfully retrieved data for META, shape: (250, 7)\n",
      "\n",
      "Processing result for symbol: AMZN\n",
      "Successfully retrieved data for AMZN, shape: (250, 7)\n",
      "\n",
      "=== Completed get_data ===\n",
      "Successfully retrieved data for 5 symbols: ['MSFT', 'AAPL', 'GOOGL', 'META', 'AMZN']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "# Set up logging with more detailed format\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Changed to DEBUG level\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout  # Ensure output goes to notebook\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Create necessary directories for the backtest system.\"\"\"\n",
    "    try:\n",
    "        # Define base directories\n",
    "        __file__ = os.path.abspath('main.ipynb')\n",
    "        base_dir = os.path.abspath(os.path.dirname(__file__))\n",
    "        data_dir = os.path.join(base_dir, 'data')\n",
    "        db_dir = os.path.join(data_dir, 'db')\n",
    "        cache_dir = os.path.join(data_dir, 'cache')\n",
    "        \n",
    "        logger.debug(f\"Setting up directories:\")\n",
    "        logger.debug(f\"Base dir: {base_dir}\")\n",
    "        logger.debug(f\"Data dir: {data_dir}\")\n",
    "        logger.debug(f\"DB dir: {db_dir}\")\n",
    "        logger.debug(f\"Cache dir: {cache_dir}\")\n",
    "        \n",
    "        # Create directories\n",
    "        Path(data_dir).mkdir(exist_ok=True)\n",
    "        Path(db_dir).mkdir(exist_ok=True)\n",
    "        Path(cache_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        # Verify directories were created\n",
    "        for dir_path in [data_dir, db_dir, cache_dir]:\n",
    "            if not os.path.exists(dir_path):\n",
    "                raise RuntimeError(f\"Failed to create directory: {dir_path}\")\n",
    "            else:\n",
    "                logger.debug(f\"Verified directory exists: {dir_path}\")\n",
    "        \n",
    "        # Create default config if it doesn't exist\n",
    "        config_path = os.path.join(base_dir, 'config.yaml')\n",
    "        if not os.path.exists(config_path):\n",
    "            logger.debug(\"Creating default config.yaml\")\n",
    "            default_config = {\n",
    "                'cache': {\n",
    "                    'max_memory_cache_size': 1000,\n",
    "                    'cache_expiry_days': 1,\n",
    "                    'update_frequency': '1d',\n",
    "                    'compression_type': 'parquet'\n",
    "                },\n",
    "                'download': {\n",
    "                    'max_retries': 3,\n",
    "                    'retry_delay': 5,\n",
    "                    'batch_size': 100,\n",
    "                    'timeout': 30\n",
    "                },\n",
    "                'validation': {\n",
    "                    'min_data_points': 50,\n",
    "                    'max_missing_pct': 0.1,\n",
    "                    'price_threshold': 0.01\n",
    "                }\n",
    "            }\n",
    "            with open(config_path, 'w') as f:\n",
    "                yaml.dump(default_config, f)\n",
    "            logger.debug(\"Created config.yaml successfully\")\n",
    "        else:\n",
    "            logger.debug(\"config.yaml already exists\")\n",
    "        \n",
    "        return {\n",
    "            'base_dir': base_dir,\n",
    "            'data_dir': data_dir,\n",
    "            'db_dir': db_dir,\n",
    "            'cache_dir': cache_dir,\n",
    "            'config_path': config_path\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in setup_directories: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def test_backtest():\n",
    "    \"\"\"Test the Backtest class and its data fetching capabilities.\"\"\"\n",
    "    logger.info(\"Starting backtest test\")\n",
    "    \n",
    "    # Set up test parameters\n",
    "    symbols = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META']\n",
    "    start_date = '2023-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    \n",
    "    try:\n",
    "        # Set up directories first\n",
    "        logger.info(\"Setting up directories...\")\n",
    "        dirs = setup_directories()\n",
    "        \n",
    "        logger.info(\"Testing with directories:\")\n",
    "        for key, value in dirs.items():\n",
    "            logger.info(f\"{key}: {value}\")\n",
    "            \n",
    "        # Verify config file\n",
    "        if not os.path.exists(dirs['config_path']):\n",
    "            raise RuntimeError(f\"Config file not found at {dirs['config_path']}\")\n",
    "        \n",
    "        # Initialize Backtest with proper config path\n",
    "        logger.info(\"Initializing Backtest class...\")\n",
    "        backtest = Backtest(config_path=dirs['config_path'])\n",
    "        \n",
    "        # Fetch historical data\n",
    "        logger.info(f\"Fetching historical data for symbols: {symbols}\")\n",
    "        historical_data = backtest.fetch_historical_data(symbols, start_date, end_date)\n",
    "        \n",
    "        # Verify data\n",
    "        if not historical_data:\n",
    "            logger.warning(\"No historical data was returned!\")\n",
    "        else:\n",
    "            logger.info(f\"Retrieved data for {len(historical_data)} symbols\")\n",
    "            \n",
    "            # Print summary statistics for each symbol\n",
    "            for symbol, df in historical_data.items():\n",
    "                logger.info(f\"\\nSummary for {symbol}:\")\n",
    "                logger.info(f\"Date Range: {df.index.min()} to {df.index.max()}\")\n",
    "                logger.info(f\"Number of trading days: {len(df)}\")\n",
    "                logger.info(\"\\nPrice Statistics:\")\n",
    "                logger.info(df['Close'].describe())\n",
    "        \n",
    "        return historical_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during testing: {str(e)}\")\n",
    "        logger.error(\"Stack trace:\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    historical_data = test_backtest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ns_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
