{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:49:50.924009Z",
     "start_time": "2021-04-15T19:49:50.922066Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:49:52.141883Z",
     "start_time": "2021-04-15T19:49:50.925252Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import backtrader as bt\n",
    "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
    "from pypfopt.exceptions import OptimizationError\n",
    "import quantstats as qs\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:49:52.159076Z",
     "start_time": "2021-04-15T19:49:52.145590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup logging configuration\n",
    "def setup_logging():\n",
    "    formatter = logging.Formatter(\n",
    "        fmt='[%(asctime)s.%(msecs)03d]: %(levelname)s: %(message)s',\n",
    "        datefmt='%H:%M:%S'\n",
    "    )\n",
    "    \n",
    "    # Setup handlers for different log levels\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "\n",
    "    error_handler = logging.StreamHandler(sys.stderr)\n",
    "    error_handler.setFormatter(formatter)\n",
    "    error_handler.setLevel(logging.ERROR)\n",
    "\n",
    "    # Debug handler for detailed logs\n",
    "    debug_handler = logging.StreamHandler(sys.stdout)\n",
    "    debug_handler.setFormatter(formatter)\n",
    "    debug_handler.setLevel(logging.DEBUG)\n",
    "    \n",
    "    logger = logging.getLogger('Algorithm')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.handlers = []  # Remove existing handlers\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(error_handler)\n",
    "    logger.addHandler(debug_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "log = setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market calendar for trading days\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "valid_dates = nyse.valid_days(start_date='2013-01-01', end_date='2017-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:49:52.166662Z",
     "start_time": "2021-04-15T19:49:52.159964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "MONTH = 21             # Trading days in a month\n",
    "YEAR = 12 * MONTH      # Trading days in a year\n",
    "N_LONGS = 50           # Number of long positions\n",
    "N_SHORTS = 50          # Number of short positions\n",
    "MIN_POS = 5            # Minimum positions required in each direction\n",
    "VOL_SCREEN = 500       # Top 500 most liquid stocks\n",
    "MAX_POS_SIZE = 0.10    # Maximum 10% in any single position\n",
    "COMMISSION = 0.00075   # Commission rate\n",
    "REBALANCE_FREQUENCY = 5  # Rebalance every 5 trading days\n",
    "capital_base = 1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:49:52.174450Z",
     "start_time": "2021-04-15T19:49:52.167433Z"
    }
   },
   "outputs": [],
   "source": [
    "class FactorPipeline:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def compute_mean_reversion(self):\n",
    "        results = {}\n",
    "        for symbol, hist in self.data.items():\n",
    "            try:\n",
    "                close_prices = hist['Close']\n",
    "                monthly_returns = close_prices.resample('M').last().pct_change()\n",
    "                if len(monthly_returns) >= 12:\n",
    "                    latest_return = monthly_returns.iloc[-1]\n",
    "                    mean_annual = monthly_returns.rolling(12).mean().iloc[-1]\n",
    "                    std_annual = monthly_returns.rolling(12).std().iloc[-1]\n",
    "                    if pd.notnull(std_annual) and std_annual != 0:\n",
    "                        factor = (latest_return - mean_annual) / std_annual\n",
    "                        results[symbol] = factor\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error calculating factor for {symbol}: {e}\")\n",
    "        return pd.Series(results)\n",
    "\n",
    "    def filter_by_volume(self, lookback_days: int = 30):\n",
    "        volume_data = {}\n",
    "        for symbol, hist in self.data.items():\n",
    "            avg_volume = hist['Volume'].tail(lookback_days).mean()\n",
    "            volume_data[symbol] = avg_volume\n",
    "        volume_series = pd.Series(volume_data)\n",
    "        return volume_series.nlargest(VOL_SCREEN).index.tolist()\n",
    "\n",
    "    def rank_stocks(self):\n",
    "        factors = self.compute_mean_reversion()\n",
    "        ranked = factors.sort_values(ascending=True)\n",
    "        self.longs = ranked.head(N_LONGS).index.tolist()\n",
    "        self.shorts = ranked.tail(N_SHORTS).index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YahooDataFeed(bt.feeds.PandasData):\n",
    "    \"\"\"Custom data feed for Yahoo Finance data\"\"\"\n",
    "    params = (\n",
    "        ('datetime', None),\n",
    "        ('open', 'Open'),\n",
    "        ('high', 'High'),\n",
    "        ('low', 'Low'),\n",
    "        ('close', 'Close'),\n",
    "        ('volume', 'Volume'),\n",
    "        ('openinterest', None),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Reversion Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:49:52.182556Z",
     "start_time": "2021-04-15T19:49:52.175707Z"
    }
   },
   "outputs": [],
   "source": [
    "class MeanReversionSignals:\n",
    "    \"\"\"Calculate mean reversion signals for a universe of stocks\"\"\"\n",
    "    \n",
    "    def __init__(self, symbols: List[str], start_date: datetime, end_date: datetime):\n",
    "        self.symbols = symbols\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.data = None\n",
    "        \n",
    "    def fetch_data(self):\n",
    "        \"\"\"Fetch data for all symbols\"\"\"\n",
    "        logger.info(\"Fetching data for %d symbols\", len(self.symbols))\n",
    "        all_data = {}\n",
    "        \n",
    "        # Fetch data for all symbols at once for efficiency\n",
    "        try:\n",
    "            data = yf.download(\n",
    "                self.symbols,\n",
    "                start=self.start_date,\n",
    "                end=self.end_date,\n",
    "                group_by='ticker',\n",
    "                auto_adjust=True\n",
    "            )\n",
    "            \n",
    "            # If only one symbol, data structure is different\n",
    "            if len(self.symbols) == 1:\n",
    "                symbol = self.symbols[0]\n",
    "                all_data[symbol] = data\n",
    "            else:\n",
    "                # Multiple symbols\n",
    "                for symbol in self.symbols:\n",
    "                    if symbol in data.columns.levels[0]:\n",
    "                        symbol_data = data[symbol].copy()\n",
    "                        if not symbol_data.empty:\n",
    "                            all_data[symbol] = symbol_data\n",
    "                            \n",
    "            logger.info(f\"Successfully fetched data for {len(all_data)} symbols\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching data: {e}\")\n",
    "            \n",
    "        self.data = all_data\n",
    "        if not self.data:\n",
    "            raise ValueError(\"No data was fetched for any symbols\")\n",
    "            \n",
    "        return self.data\n",
    "    \n",
    "    def calculate_mean_reversion_factor(self) -> pd.Series:\n",
    "        \"\"\"Calculate mean reversion factor for all stocks\"\"\"\n",
    "        if self.data is None:\n",
    "            self.fetch_data()\n",
    "            \n",
    "        if not self.data:\n",
    "            raise ValueError(\"No data available for calculation\")\n",
    "            \n",
    "        results = {}\n",
    "        for symbol, hist in self.data.items():\n",
    "            try:\n",
    "                # Get the closing prices\n",
    "                close_prices = hist['Close'] if 'Close' in hist.columns else hist['Adj Close']\n",
    "                \n",
    "                # Calculate monthly returns\n",
    "                monthly_returns = close_prices.resample('M').last().pct_change()\n",
    "                \n",
    "                if len(monthly_returns) >= 12:\n",
    "                    latest_return = monthly_returns.iloc[-1]\n",
    "                    mean_annual = monthly_returns.rolling(12).mean().iloc[-1]\n",
    "                    std_annual = monthly_returns.rolling(12).std().iloc[-1]\n",
    "                    \n",
    "                    if pd.notnull(std_annual) and std_annual != 0:\n",
    "                        factor = (latest_return - mean_annual) / std_annual\n",
    "                        results[symbol] = factor\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error calculating factor for {symbol}: {e}\")\n",
    "        \n",
    "        if not results:\n",
    "            raise ValueError(\"Could not calculate factors for any symbols\")\n",
    "            \n",
    "        return pd.Series(results)\n",
    "    \n",
    "    def filter_by_volume(self, lookback_days: int = 30) -> List[str]:\n",
    "        \"\"\"Filter stocks by trading volume\"\"\"\n",
    "        volume_data = {}\n",
    "        \n",
    "        for symbol, hist in self.data.items():\n",
    "            avg_volume = hist['Volume'].tail(lookback_days).mean()\n",
    "            volume_data[symbol] = avg_volume\n",
    "            \n",
    "        volume_series = pd.Series(volume_data)\n",
    "        return volume_series.nlargest(VOL_SCREEN).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanReversionStrategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('month_length', MONTH),\n",
    "        ('year_length', YEAR),\n",
    "        ('n_longs', N_LONGS),\n",
    "        ('n_shorts', N_SHORTS),\n",
    "        ('min_positions', MIN_POS),\n",
    "        ('max_pos_size', MAX_POS_SIZE),\n",
    "        ('rebalance_freq', REBALANCE_FREQUENCY)\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.orders = {}\n",
    "        self.current_weights = {}\n",
    "        self.last_rebalance = 0\n",
    "        self.tracked_metrics = []\n",
    "\n",
    "        self.monthly_returns = {}\n",
    "        self.volumes = {}\n",
    "        for data in self.datas:\n",
    "            self.monthly_returns[data._name] = bt.indicators.PctChange(\n",
    "                data.close, period=self.p.month_length\n",
    "            )\n",
    "            self.volumes[data._name] = bt.indicators.SMA(\n",
    "                data.volume, period=30\n",
    "            )\n",
    "\n",
    "    def before_trading_start(self):\n",
    "        \"\"\"Fetch and rank stocks before each trading session\"\"\"\n",
    "        if self.data.datetime.date(0) not in valid_dates:\n",
    "            return\n",
    "\n",
    "        # Initialize the pipeline with the latest data\n",
    "        self.pipeline = FactorPipeline(self.fetch_latest_data())\n",
    "        self.pipeline.rank_stocks()\n",
    "\n",
    "        # Store the long and short stocks for use in the next trading step\n",
    "        self.longs = self.pipeline.longs\n",
    "        self.shorts = self.pipeline.shorts\n",
    "\n",
    "\n",
    "    def get_volume_filtered_universe(self):\n",
    "        vol_data = {}\n",
    "        for data in self.datas:\n",
    "            vol = self.volumes[data._name][0]\n",
    "            if not np.isnan(vol):\n",
    "                vol_data[data._name] = vol\n",
    "        if not vol_data:\n",
    "            return []\n",
    "        vol_series = pd.Series(vol_data)\n",
    "        vol_cutoff = vol_series.quantile(0.25)\n",
    "        return vol_series[vol_series >= vol_cutoff].index.tolist()\n",
    "\n",
    "    def optimize_portfolio(self, prices: pd.DataFrame, short: bool = False) -> Dict[str, float]:\n",
    "        try:\n",
    "            returns = expected_returns.mean_historical_return(prices=prices, frequency=252)\n",
    "            cov = risk_models.sample_cov(prices=prices, frequency=252)\n",
    "            weight_bounds = (0, self.p.max_pos_size) if not short else (-self.p.max_pos_size, 0)\n",
    "            ef = EfficientFrontier(expected_returns=returns, cov_matrix=cov, weight_bounds=weight_bounds, solver='SCS')\n",
    "            ef.max_sharpe()\n",
    "            weights = ef.clean_weights()\n",
    "            if short:\n",
    "                return {asset: -weight for asset, weight in weights.items()}\n",
    "            return weights\n",
    "        except OptimizationError as e:\n",
    "            logger.warning(f\"Portfolio optimization failed: {e}, using equal weights\")\n",
    "            if short:\n",
    "                return {asset: -1 / len(prices.columns) for asset in prices.columns}\n",
    "            return {asset: 1 / len(prices.columns) for asset in prices.columns}\n",
    "\n",
    "    def next(self):\n",
    "        if len(self) - self.last_rebalance < self.p.rebalance_freq:\n",
    "            return\n",
    "        self.last_rebalance = len(self)\n",
    "        logger.info(f\"Processing date: {self.data0.datetime.date(0)}\")\n",
    "\n",
    "        valid_universe = self.get_volume_filtered_universe()\n",
    "        if not valid_universe:\n",
    "            logger.warning(\"No stocks meet volume criteria\")\n",
    "            return\n",
    "\n",
    "        factors = {}\n",
    "        prices = pd.DataFrame()\n",
    "        for data in self.datas:\n",
    "            if data._name not in valid_universe:\n",
    "                continue\n",
    "            if len(data) > self.p.year_length:\n",
    "                prices[data._name] = data.close.get(size=252)\n",
    "                monthly_ret = self.monthly_returns[data._name][0]\n",
    "                returns = [self.monthly_returns[data._name][-i] for i in range(12)]\n",
    "                valid_returns = [r for r in returns if not np.isnan(r)]\n",
    "                if len(valid_returns) >= 6:\n",
    "                    mean_annual = np.nanmean(valid_returns)\n",
    "                    std_annual = np.nanstd(valid_returns)\n",
    "                    if std_annual > 0 and not np.isnan(monthly_ret):\n",
    "                        factors[data._name] = float((monthly_ret - mean_annual) / std_annual)\n",
    "                        logger.info(f\"Factor for {data._name}: {factors[data._name]:.4f}\")\n",
    "\n",
    "        if len(factors) >= 2 * self.p.min_positions:\n",
    "            sorted_factors = sorted(factors.items(), key=lambda x: x[1])\n",
    "            longs = [item[0] for item in sorted_factors[:self.p.n_longs]]\n",
    "            shorts = [item[0] for item in sorted_factors[-self.p.n_shorts:]]\n",
    "            logger.info(f\"Long positions: {longs}\")\n",
    "            logger.info(f\"Short positions: {shorts}\")\n",
    "            if len(longs) >= self.p.min_positions and len(shorts) >= self.p.min_positions:\n",
    "                try:\n",
    "                    long_prices = prices[longs]\n",
    "                    short_prices = prices[shorts]\n",
    "                    long_weights = self.optimize_portfolio(long_prices)\n",
    "                    short_weights = self.optimize_portfolio(short_prices, short=True)\n",
    "                    logger.info(f\"Long weights: {long_weights}\")\n",
    "                    logger.info(f\"Short weights: {short_weights}\")\n",
    "                    for data in self.datas:\n",
    "                        symbol = data._name\n",
    "                        if self.getposition(data).size and self.broker.get_orders_open(data):\n",
    "                            continue\n",
    "                        target_weight = long_weights.get(symbol, 0) + short_weights.get(symbol, 0)\n",
    "                        target_weight = np.clip(target_weight, -self.p.max_pos_size, self.p.max_pos_size)\n",
    "                        current_weight = self.current_weights.get(symbol, 0)\n",
    "                        if abs(target_weight - current_weight) > 0.01:\n",
    "                            logger.info(f\"Placing order for {symbol}: target weight = {target_weight:.4f}\")\n",
    "                            self.order_target_percent(data, target_weight)\n",
    "                            self.current_weights[symbol] = target_weight\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Portfolio optimization failed: {e}\")\n",
    "            else:\n",
    "                logger.warning(\"Insufficient positions meet criteria\")\n",
    "        else:\n",
    "            logger.warning(f\"Not enough factors ({len(factors)}) for minimum positions ({2 * self.p.min_positions})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:59:47.818235Z",
     "start_time": "2021-04-15T19:49:52.262074Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_backtest(symbols: List[str], \n",
    "                 start_date: datetime,\n",
    "                 end_date: datetime,\n",
    "                 initial_capital: float = 1e7):\n",
    "    \"\"\"Run backtest with the strategy\"\"\"\n",
    "\n",
    "    if not symbols:\n",
    "        raise ValueError(\"No symbols provided for backtest\")\n",
    "\n",
    "    logger.info(\"Fetching data for the pipeline...\")\n",
    "\n",
    "    # Step 1: Fetch data for all symbols\n",
    "    all_data = {}\n",
    "    for symbol in symbols:\n",
    "        df = yf.download(symbol, start=start_date, end=end_date)\n",
    "        if not df.empty:\n",
    "            all_data[symbol] = df\n",
    "            logger.info(f\"Fetched data for {symbol}\")\n",
    "\n",
    "    # Step 2: Create a FactorPipeline instance\n",
    "    pipeline = FactorPipeline(all_data)\n",
    "\n",
    "    # Step 3: Filter by volume and compute rankings\n",
    "    filtered_symbols = pipeline.filter_by_volume(lookback_days=30)\n",
    "    pipeline.rank_stocks()\n",
    "\n",
    "    # Get the final list of symbols to trade: longs and shorts\n",
    "    symbols_to_trade = set(pipeline.longs + pipeline.shorts)\n",
    "\n",
    "    # Step 4: Setup Backtrader\n",
    "    cerebro = bt.Cerebro()\n",
    "    cerebro.addstrategy(MeanReversionStrategy)\n",
    "    cerebro.addanalyzer(bt.analyzers.Returns, _name='returns')\n",
    "    cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')\n",
    "    cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe')\n",
    "    cerebro.addobserver(bt.observers.Value)\n",
    "\n",
    "    # Step 5: Add filtered data to Backtrader\n",
    "    logger.info(\"Adding filtered data to the backtest...\")\n",
    "\n",
    "    for symbol in symbols_to_trade:\n",
    "        if symbol in all_data:\n",
    "            df = all_data[symbol]\n",
    "            feed = YahooDataFeed(\n",
    "                dataname=df,\n",
    "                name=symbol,\n",
    "                fromdate=start_date,\n",
    "                todate=end_date\n",
    "            )\n",
    "            cerebro.adddata(feed)\n",
    "            logger.info(f\"Added {symbol} to backtest\")\n",
    "\n",
    "    # Step 6: Set Broker Parameters\n",
    "    cerebro.broker.setcash(initial_capital)\n",
    "    cerebro.broker.setcommission(commission=COMMISSION, margin=False, mult=1.0)\n",
    "    cerebro.broker.set_slippage_perc(0.0005)\n",
    "\n",
    "    # Step 7: Run Backtest\n",
    "    logger.info(\"Starting backtest...\")\n",
    "    results = cerebro.run()\n",
    "    strat = results[0]\n",
    "\n",
    "    # Step 8: Extract Backtest Results\n",
    "    final_value = cerebro.broker.getvalue()\n",
    "    returns = (final_value - initial_capital) / initial_capital\n",
    "\n",
    "    logger.info(f\"Final Portfolio Value: ${final_value:,.2f}\")\n",
    "    logger.info(f\"Return: {returns:.2%}\")\n",
    "\n",
    "    # Step 9: Extract Values for Analysis\n",
    "    values = strat.observers.value.lines.value.array[::2]\n",
    "    dates = [bt.num2date(x) for x in strat.datas[0].datetime.array]\n",
    "\n",
    "    # Ensure lengths match\n",
    "    min_length = min(len(values), len(dates))\n",
    "    values = values[:min_length]\n",
    "    dates = dates[:min_length]\n",
    "\n",
    "    # Create DataFrame with daily values\n",
    "    df_values = pd.DataFrame({\n",
    "        'portfolio_value': values\n",
    "    }, index=pd.DatetimeIndex(dates))\n",
    "\n",
    "    # Calculate returns properly for quantstats\n",
    "    df_values = df_values.resample('D').last().fillna(method='ffill')\n",
    "    portfolio_returns = df_values['portfolio_value'].pct_change().dropna()\n",
    "\n",
    "    # Step 10: Save Basic Metrics to File\n",
    "    metrics_data = {\n",
    "        'Total Return': f\"{returns:.2%}\",\n",
    "        'Final Portfolio Value': f\"${final_value:,.2f}\",\n",
    "        'Sharpe Ratio': strat.analyzers.sharpe.get_analysis()['sharperatio'],\n",
    "        'Max Drawdown': f\"{strat.analyzers.drawdown.get_analysis()['max']['drawdown']:.2%}\"\n",
    "    }\n",
    "\n",
    "    with open('backtest_results.txt', 'w') as f:\n",
    "        for metric, value in metrics_data.items():\n",
    "            f.write(f\"{metric}: {value}\\n\")\n",
    "\n",
    "    return results, cerebro, start_date, end_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:59:48.896101Z",
     "start_time": "2021-04-15T19:59:47.819858Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:42:01] INFO: Fetching S&P 500 symbols for the backtest...\n",
      "[00:42:02] INFO: Retrieved 503 S&P 500 symbols\n",
      "[00:42:02] INFO: Validating symbols...\n",
      "[00:42:04] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:04] ERROR: ['ABNB']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:07] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:07] ERROR: ['AMTM']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:10] INFO: Validated 50/503 symbols. Found 48 valid symbols.\n",
      "[00:42:16] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:16] ERROR: ['CARR']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:18] INFO: Validated 100/503 symbols. Found 97 valid symbols.\n",
      "[00:42:22] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:22] ERROR: ['CEG']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:23] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:23] ERROR: ['CTVA']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:24] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:24] ERROR: ['CRWD']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:26] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:26] ERROR: ['DAY']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:27] INFO: Validated 150/503 symbols. Found 143 valid symbols.\n",
      "[00:42:29] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:29] ERROR: ['DOW']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:35] INFO: Validated 200/503 symbols. Found 192 valid symbols.\n",
      "[00:42:36] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:36] ERROR: ['FOXA']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n",
      "[00:42:37] ERROR: \n",
      "1 Failed download:\n",
      "[00:42:37] ERROR: ['FOX']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2013-01-01 00:00:00 -> 2017-01-01 00:00:00) (Yahoo error = \"Data doesn\\'t exist for startDate = 1357016400, endDate = 1483246800\")')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "def get_sp500_symbols():\n",
    "    \"\"\"Get current S&P 500 constituents using Wikipedia\"\"\"\n",
    "    try:\n",
    "        # Get SP500 list from Wikipedia\n",
    "        url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "        tables = pd.read_html(url)\n",
    "        sp500_table = tables[0]\n",
    "        symbols = sp500_table['Symbol'].tolist()\n",
    "        \n",
    "        # Clean symbols (remove special characters, etc.)\n",
    "        symbols = [sym.replace('.', '-') for sym in symbols]\n",
    "        logger.info(f\"Retrieved {len(symbols)} S&P 500 symbols\")\n",
    "        return symbols\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching S&P 500 symbols: {e}\")\n",
    "        return []\n",
    "\n",
    "def validate_symbols(symbols, start_date, end_date):\n",
    "    \"\"\"Validate which symbols have data for the entire period\"\"\"\n",
    "    valid_symbols = []\n",
    "    \n",
    "    logger.info(\"Validating symbols...\")\n",
    "    total = len(symbols)\n",
    "    \n",
    "    for i, symbol in enumerate(symbols, 1):\n",
    "        try:\n",
    "            # Try to get a small amount of data to verify the symbol exists\n",
    "            df = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
    "            if not df.empty and len(df) > 50:  # Require at least 50 days of data\n",
    "                valid_symbols.append(symbol)\n",
    "            \n",
    "            if i % 50 == 0:  # Log progress every 50 symbols\n",
    "                logger.info(f\"Validated {i}/{total} symbols. Found {len(valid_symbols)} valid symbols.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error validating {symbol}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    logger.info(f\"Found {len(valid_symbols)} valid symbols out of {total}\")\n",
    "    return valid_symbols\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the backtest\"\"\"\n",
    "    start_date = datetime(2013, 1, 1)\n",
    "    end_date = datetime(2017, 1, 1)\n",
    "\n",
    "    # Step 1: Get and validate symbols\n",
    "    logger.info(\"Fetching S&P 500 symbols for the backtest...\")\n",
    "    sp500_symbols = get_sp500_symbols()\n",
    "\n",
    "    if not sp500_symbols:\n",
    "        logger.error(\"No symbols found for the backtest.\")\n",
    "        return\n",
    "\n",
    "    # Validate the symbols to make sure they have sufficient data\n",
    "    valid_symbols = validate_symbols(sp500_symbols, start_date, end_date)\n",
    "\n",
    "    if not valid_symbols:\n",
    "        logger.error(\"No valid symbols found after validation.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Run the backtest with validated symbols\n",
    "    try:\n",
    "        logger.info(\"Starting the backtest...\")\n",
    "        results, cerebro, start, end = run_backtest(\n",
    "            symbols=valid_symbols,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            initial_capital=1e7\n",
    "        )\n",
    "        logger.info(\"Backtest completed successfully.\")\n",
    "\n",
    "        return results, cerebro, start, end\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during the backtest: {e}\")\n",
    "\n",
    "results, cerebro, start, end = main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist Results for use with `pyfolio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:59:48.930171Z",
     "start_time": "2021-04-15T19:59:48.897706Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_backtest_results(cerebro, results):\n",
    "    \"\"\"Analyze backtest results and create visualizations\"\"\"\n",
    "    \n",
    "    # Extract strategy instance\n",
    "    strat = results[0]\n",
    "\n",
    "    # Get portfolio values and associated datetimes from Backtrader\n",
    "    portfolio_values = strat.observers.value.lines.value.array\n",
    "    dates = [bt.num2date(d) for d in strat.datas[0].datetime.array][:len(portfolio_values)]\n",
    "\n",
    "    # Create the portfolio value series using the correct length and date range\n",
    "    # Drop duplicate dates to avoid having multiple records for a single day\n",
    "    unique_dates, unique_portfolio_values = [], []\n",
    "    for i, date in enumerate(dates):\n",
    "        if i == 0 or date.date() != dates[i-1].date():\n",
    "            unique_dates.append(date)\n",
    "            unique_portfolio_values.append(portfolio_values[i])\n",
    "\n",
    "    # Create portfolio series using daily data (unique dates)\n",
    "    portfolio_series = pd.Series(unique_portfolio_values, index=pd.to_datetime(unique_dates))\n",
    "    returns = portfolio_series.pct_change().dropna()\n",
    "\n",
    "    # Extract orders and create a transactions DataFrame\n",
    "    transactions = []\n",
    "    for order in strat._orders:\n",
    "        if order.status == bt.Order.Completed:\n",
    "            transactions.append({\n",
    "                'dt': bt.num2date(order.executed.dt),\n",
    "                'symbol': order.data._name,\n",
    "                'amount': order.executed.size,\n",
    "                'price': order.executed.price,\n",
    "                'txn_dollars': order.executed.size * order.executed.price\n",
    "            })\n",
    "    transactions_df = pd.DataFrame(transactions)\n",
    "\n",
    "    if not transactions_df.empty:\n",
    "        transactions_df.set_index('dt', inplace=True)\n",
    "\n",
    "    # Save results to HDF5\n",
    "    with pd.HDFStore('backtests.h5') as store:\n",
    "        store.put('returns/mean_reversion', returns)\n",
    "        if not transactions_df.empty:\n",
    "            store.put('transactions/mean_reversion', transactions_df)\n",
    "\n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(nrows=2, figsize=(14, 8))\n",
    "\n",
    "    # Plot cumulative returns\n",
    "    cum_returns = (1 + returns).cumprod() - 1\n",
    "    cum_returns.plot(ax=axes[0], title='Cumulative Returns')\n",
    "    axes[0].set_ylabel('Return (%)')\n",
    "\n",
    "    # Plot cumulative transactions\n",
    "    if not transactions_df.empty:\n",
    "        transactions_df.groupby(transactions_df.index.date)['txn_dollars'].sum().cumsum().plot(\n",
    "            ax=axes[1], title='Cumulative Transactions')\n",
    "        axes[1].set_ylabel('Transaction Value ($)')\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Generate quantstats report\n",
    "    qs.reports.html(returns,\n",
    "                   output='mean_reversion_report.html',\n",
    "                   title='Mean Reversion Strategy Analysis')\n",
    "\n",
    "    return returns, transactions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:59:49.064963Z",
     "start_time": "2021-04-15T19:59:48.931263Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_strategies(returns_dict, transactions_dict):\n",
    "    \"\"\"Compare multiple strategy results\"\"\"\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 10))\n",
    "    \n",
    "    # Plot returns\n",
    "    for name, returns in returns_dict.items():\n",
    "        cum_returns = (1 + returns).cumprod() - 1\n",
    "        cum_returns.plot(ax=axes[0][0], label=name)\n",
    "    axes[0][0].set_title('Cumulative Returns Comparison')\n",
    "    axes[0][0].legend()\n",
    "    \n",
    "    # Plot transactions\n",
    "    for name, txns in transactions_dict.items():\n",
    "        if not txns.empty:\n",
    "            txns.groupby(txns.index.date)['txn_dollars'].sum().cumsum().plot(\n",
    "                ax=axes[0][1], label=name)\n",
    "    axes[0][1].set_title('Cumulative Transactions Comparison')\n",
    "    axes[0][1].legend()\n",
    "    \n",
    "    # Add performance metrics\n",
    "    metrics = []\n",
    "    for name, returns in returns_dict.items():\n",
    "        sharpe = qs.stats.sharpe(returns)\n",
    "        max_dd = qs.stats.max_drawdown(returns)\n",
    "        total_return = (cum_returns.iloc[-1]) if not returns.empty else 0.0\n",
    "        metrics.append({\n",
    "            'Strategy': name,\n",
    "            'Sharpe Ratio': sharpe,\n",
    "            'Max Drawdown': max_dd,\n",
    "            'Total Return': total_return\n",
    "        })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics).set_index('Strategy')\n",
    "    \n",
    "    # Plot metrics\n",
    "    metrics_df[['Sharpe Ratio']].plot(kind='bar', ax=axes[1][0])\n",
    "    axes[1][0].set_title('Sharpe Ratio Comparison')\n",
    "    metrics_df[['Max Drawdown']].plot(kind='bar', ax=axes[1][1])\n",
    "    axes[1][1].set_title('Max Drawdown Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:59:49.417803Z",
     "start_time": "2021-04-15T19:59:49.066143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "def run_analysis(cerebro, results, start_date, end_date):\n",
    "    \"\"\"Analyze and compare strategy results\"\"\"\n",
    "    \n",
    "    # Analyze mean reversion strategy\n",
    "    returns, transactions = analyze_backtest_results(cerebro, results, start_date, end_date)\n",
    "    \n",
    "    # Load equal weight strategy results (if available)\n",
    "    try:\n",
    "        with pd.HDFStore('backtests.h5') as store:\n",
    "            returns_ew = store['returns/equal_weight']\n",
    "            tx_ew = store['transactions/equal_weight']\n",
    "            \n",
    "            # Compare strategies\n",
    "            returns_dict = {\n",
    "                'Mean Reversion': returns,\n",
    "                'Equal Weight': returns_ew\n",
    "            }\n",
    "            \n",
    "            transactions_dict = {\n",
    "                'Mean Reversion': transactions,\n",
    "                'Equal Weight': tx_ew\n",
    "            }\n",
    "            \n",
    "            metrics_df = compare_strategies(returns_dict, transactions_dict)\n",
    "            print(\"\\nStrategy Comparison:\")\n",
    "            print(metrics_df)\n",
    "            \n",
    "    except KeyError:\n",
    "        print(\"Equal weight strategy results not found. Showing only mean reversion results.\")\n",
    "    \n",
    "    return returns, transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T19:59:50.077791Z",
     "start_time": "2021-04-15T19:59:49.418674Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cerebro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m returns, transactions \u001b[38;5;241m=\u001b[39m analyze_backtest_results(\u001b[43mcerebro\u001b[49m, results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cerebro' is not defined"
     ]
    }
   ],
   "source": [
    "returns, transactions = run_analysis(cerebro, results, start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ns_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252.628px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
